% \subsection{The Implementation Evaluation Results }
% \label{sec:adapt-impleval}

\paragraph{Set Up}
We implemented $\THESYSTEM$ as a tool that takes a labeled command as input 
and outputs two upper bounds on the program adaptivity and the number of query requests, respectively.
This implementation consists of components for the 
abstract control flow graph generation,
the edge estimation, and the weight estimation in Ocaml, 
and of an implementation of the $\pathsearch$ algorithm in Python.
% The OCaml program takes the labeled command as input and outputs the program-based dependency graph and
% the abstract transition graph, which we
% feed into the Python program and the Python program provides the adaptivity upper bound and the query number \highlight{upper bound} as the final output.


\paragraph{Accuracy and Performance}
\input{eval-table}
We evaluate our implementation in terms of its accuracy and performance in estimating the adaptivity
through $25$ example programs (summary in Table~\ref{tb:adapt-imp}).
For each example we compare the true accuracy with the estimated adaptivity, and we report the estimated number of queries, the L.O.C and the running time for the graph construction (graph), the weight estimation (weight) and the adaptivity computation ($\pathsearch$).
The set of examples includes the ones we have described before, such as two rounds $\kw{twoRounds(k)}$ in
Fig.~\ref{fig:overview-example}(a) and multiple rounds $ \kw{mR(k)}$ and its variants $\kw{mROdd(k)}$ $\kw{mROdd(k)}$,
a logistic regression algorithm with gradient descent (short for $\kw{LRGD}$),
handcrafted programs from the $6^{th}$ ($\kw{seqRV}$) to $19^{th}$ ($\kw{loop2R}$) based on benchmarks from the work by Gulwani et al.~\cite{GulwaniJK09}. These examples have small sizes but complex structures to test the programs under different situations including
data dependency, control dependency, and the multiple paths nested loop with related counters, etc. The names of these programs obey the convention that,
$\kw{if}$ means there is an if control in the program;
$\kw{loop}$ means there is a while loop and $\kw{loop2}$ represents two levels nested loop in the program;
$\kw{C}$ denotes Control;
$\kw{D}$ for Dependency; $\kw{V}$ for Variable;
$\kw{M}$ for Multiple; $\kw{P}$ for Path and $\kw{R}$ for Related.
The last six programs are synthesized programs composed of the previous programs in order to test the performance limitation when the input program is large. 


In terms of accuracy, our tool provides a tight
upper bound on the adaptivity for the most of those examples. 
 For the $4^{th}$ program $\kw{mROdd(k)}$, $\THESYSTEM$ outputs an over-approximated upper bound 
 $2 + \max(1, 2k)$ because of the path-insensitive nature of the weight estimation algorithm, as discussed in Section~\ref{sec:examples}. 
 Similarly for the $17^{th}$ example $\kw{loopM}$. 
$\THESYSTEM$ outputs $1 + \max(1, k) $ for the $5^{th}$ program $\kw{mRSingle(k)}$,  tight by our adaptvitiy definition (Definition~\ref{def:trace_adapt}).
However, Definition~\ref{def:trace_adapt} does not capture precisely the accuracy  of $\kw{mRSingle(k)}$,
and the result is still an over-approximation.

In terms of performance, our tool can quickly construct the graph, estimate the weight,
and provide the adaptivity upper bound for the first $19$ examples.
 However, when it comes to complicated examples with multiple high-level nest loops such as $tRCom$ (two $2-$level and three single-level while loops), $jumbo$ (one $2-$level and two single-level while loops) and $big$ (two $3-$level, three $2-$level and one single-level while loops),
our tool can not handle them. The performance bottleneck is the reachability bound analysis algorithm used to compute the weights.
We can see how the time grows dramatically from $85.9$ seconds for the $20^{th}$ example $mR(k,N)$ with only one $3-$level nest while loop,
to $5104$ seconds ($85$ minutes) for the $21^{th}$ example $\kw{mRCom}$ who has two $3-$level nested while loops. 
Notice, that even though the example $\kw{seqCom}$ has the largest size of $502$ lines 
of code, our tool can still quickly handle it because $\kw{seqCom}$ does not have loops. Fortunately, examples with many nested loops are not common in the data analysis area. 

% \remove{We first evaluate our implementation in terms of its accuracy and performance in estimating the adaptivity
% To do this we consider {through} $23$ example programs with the evaluation results shown in  Table~\ref{tb:adapt-imp}.
% We show the accuracy of our tool by the adapativity, the estimated adaptivity and query number upper bound $A_{est}$ and $query\#$ of these $23$ examples,
% the performance through the size of examples(L.O.C) and running time which consists of graph construction(graph), weight estimation(weight) and adaptivity computation ($\pathsearch$).   } 
% \remove{In this table,
% the first column is the name of each program, the second column is the program adaptivity,
% the third column is the output of the $\THESYSTEM$ implementation, which consists of two expressions:
% the first one is the upper bound for adaptivity and the second one is the 
% upper bound for the total number of query requests in the program. And the last column is the performance evaluation w.r.t. the program size in terms of lines of code.
% The performance evaluation contains three parts. The first part is the running time of the Ocaml code, which parses the program and generates the $\progG(c)$.
% The second and third parts are the running times of the reachability bound analysis algorithm
% and the adaptivity computation algorithm, $\pathsearch(c)$.}

% \remove{The examples show a wide range of values for their adaptivity. 
% The first two programs $\kw{twoRounds(k)}$, $ \kw{mR(k)}$ are the same as Fig.~\ref{fig:overview-example}(a) and Fig.~\ref{fig:multipleRounds}(a).
% $\THESYSTEM$ computes tight adaptivity bound for the first three examples.
% The third example is a logistic regression algorithm with gradient decent (short for LRGD).
% For the fourth program $\kw{mROdd(k)}$, $\THESYSTEM$ outputs an over-approximated upper bound $2 + \max(1, 2k)$ 
% % for the $A(c)$, which is consistent with our expectation 
% because of the path insensitive nature of the weight estimation algorithm, as discussed in Section~\ref{sec:examples}. 
% The $5^{th}$ program, $\kw{mRSingle(k)}$ is the example program in Fig.~\ref{ex:multiRoundsS}.
% $\THESYSTEM$ outputs $1 + \max(1, k) $, which is tight with respect to our adaptvitiy definition in Def.~\ref{def:trace_adapt}.
% However, because Def.~\ref{def:trace_adapt} is a loose definition of $\kw{mRSingle(k)}$'s actual adaptivity rounds,
% the result is still an over-approximation.}
% %

% \remove{The next thirteen programs in Table~\ref{tb:adapt-imp} from $6^{th}$ to $19^{th}$ row are handcrafted programs based on benchmarks from the work by Gulwani et al.~\cite{GulwaniJK09}. They all have small sizes but complex structures in order to test the programs under different situations including
% data, control dependency,
% the multiple paths nested loop with related counters, etc.
% The names of these programs obey the convention that,
% $\kw{if}$ means there is an if control in the program;
% $\kw{loop}$ means there is while loop and $\kw{loop2}$ represents two levels nested loop in the program;
% $\kw{C}$ denotes Control;
% $\kw{D}$ for Dependency; $\kw{V}$ for Variable;
% $\kw{M}$ for Multiple; $\kw{P}$ for Path and $\kw{R}$ for Related.}


% \remove{Our algorithm computes tight bounds for the adaptivity of programs from row six, $\kw{seqRV()}$ to row fourteen, $\kw{loop2MPRV(k)}$
% and over-approximate the \emph{adaptivity} for the  examples in row fifteen and sixteen because of the path-insensitive nature of the algorithm computing the weights.}

% \remove{The last six programs are synthesized programs composed of the previous programs in order to test the performance limitation when the input program is large. 
% From the evaluation results, the performance bottleneck is the reachability bound analysis algorithm used to compute the weights.}

% \remove{The reachability-bound analysis algorithm presented in Section~\ref{sec:alg_weightgen} time out after $5$ minutes when evaluating the examples $\kw{tRCom(k)}$,  $\kw{jumbo}$ and ${\kw{big(k)}}$.}

{\paragraph{Alternative Implementations}
\input{eval-table-alternatives}
 Our second evaluation shows the need of the 
components of {\THESYSTEM}. 
% \remove{For this, we implement three alternative
% versions of {\THESYSTEM} where different components are omitted or
% replaced with components with weaker guarantees. We show the
% results  of the comparison in
% Table~\ref{tb:adapt-imp-alternatives}. We use the same set of example programs as in
% Table~\ref{tb:adapt-imp} and present their estimated adaptivity
% rounds, query numbers and the running time.  For each alternative
% implementation, we marked the result in red if it is imprecise
% w.r.t. the true value.}
To this end, we present {\THESYSTEM}-I which replaces the reachability bound analysis algorithm 
with a simpler one that handles nested while loop effectively but coarsely. This allows us to get results for the $\kw{jumbo}$ and $\kw{big}$ examples.
In general, {\THESYSTEM}-I gives tight upper bounds in most examples as {\THESYSTEM} does, except for the example $\kw{loop2R}$ ($2+3k+k^2$ versus $1+3k$).
We also have another implementation {\THESYSTEM}-II obtained by removing the control flow analysis. The results are unsound (not upper bounds) for examples such as $\kw{ifCD}$, $ \kw{loopMPVCD(k)} $. 
We show the results of these algorithms in Table~\ref{tb:adapt-imp-alternatives}, we highlight in red the results that are imprecise or unsound.
}
% \remove{three alternative
% versions of {\THESYSTEM} with corresponding components omitted or
% replaced using ones with weaker guarantees in Table~\ref{tb:adapt-imp-alternatives}.
%  The first one {\THESYSTEM}-I replaces the reachability bound analysis algorithm 
% with a light one that handles nested while loop effectively but coarsely for examples $\kw{jumbo}$ and $\kw{big}$.
% In general, {\THESYSTEM}-I gives a tight upper bound in most cases as {\THESYSTEM} does.
%  The exception is the $17^{th}$ example ($\kw{loop2R}$): {\THESYSTEM} gives a tight upper bound $1+3k$ while the alternative one gives a loose bound$2+3k+k^2$.
%  We show the influence of the control flow analysis in Definition~\ref{def:feasible_flowsto} by 
%  removing it in the second implementation {\THESYSTEM}-II. The results are unsound (not upper bounds) for examples such as $\kw{ifCD}$, $ \kw{loopMPVCD(k)} $ and $\kw{loopVCD(k)} $ because 
%  of the missing consideration of control dependency.
%  We marked the result in red if it is imprecise
% w.r.t. the true value.
%  }


% \remove{1. In column {\THESYSTEM}-I, the implementation replaces the reachability bound analysis algorithm in Section~\ref{sec:alg_weightgen} with a light reachability bound analysis algorithm and computes the \emph{adaptivity} for
% $\kw{jumboS}, \kw{jumbo}$ and $\kw{big}$ effectively.
% The results show that the alternative one computes tight bounds for all the examples from line:1 to line:14
% and over-approximates the \emph{adaptivity} for $15^{th}$ and $16^{th}$ due to path-insensitivity similar to the
% $\THESYSTEM$.
% For the $17^{th}$ example ($\kw{loop2R}$), {\THESYSTEM} gives a tight upper bound $1+3k$ while the alternative one gives a loose bound$2+3k+k^2$,comparing both tables }.

% \remove{2. In {\THESYSTEM}-II, we remove the control flow analysis from Definition~\ref{def:feasible_flowsto}.
% The estimated data dependency only considers the data flow.
% However, the adaptivity should consider both the data and control flow, so results here are unsound.
% For example, program $\kw{ifCD}$, $ \kw{loopMPVCD(k)} $ and $\kw{loopVCD(k)} $ all have control dependency.
% However, the alternative implementation II in Table~\ref{tb:adapt-imp-alternatives} estimates the adapvitiy rounds of $2$ because it fails to identify the dependency through control flow.
% }
% 3. In {\THESYSTEM}-III, we remove the reaching definition analysis from Section~\ref{sec:alg_edgegen}.
% The Definition~\ref{def:feasible_flowsto} is replaced by a simple data flow analysis without looking into the variable liveness.
% As a result, the estimated data dependency result contains the dependency relation between variables that is ``dead''. In other words, it over-approximates the variable may-dependency relation.

% \remove{3. In {\THESYSTEM}-III, we remove the reachability bound estimation from Section~\ref{sec:alg_weightgen}.
% We assign the weight $1$ to every labeled variable on the estimated dependency graph.
% The adaptivity estimation results are all integers and does not depend on any program inputs.
% When instantiating the input variable with varied values, this estimated result is either greater or smaller than the true adaptivity.}

% \remove{In the last column, we present only the performance of the {\THESYSTEM}-I to compare the
% light reachability-bound analysis implementation with the original reachability-bound analysis.
% The performance of {\THESYSTEM}-II is similar to {\THESYSTEM} because they are based on the same
% reachability-bound analysis implementation. For the same reason, the {\THESYSTEM}-III has slightly better
% running time than {\THESYSTEM}-I.
% Overall, {\THESYSTEM} gives accurate estimated
% adaptivity upper bounds.}
% and analysis framework $\THESYSTEM$.


\paragraph{Effectiveness Evaluation}
\input{eval-table-generalization}
In our last evaluation, we consider the effectiveness of {\THESYSTEM} in terms of reducing the generalization error of real-world data analysis programs.
%  from Sklearn machine learn benchmark sets and research paper~\cite{Jamieson2015TheAO}.
We do this by considering a set of benchmarks including 
nine classical data analyses taken from examples in Table~\ref{tb:adapt-imp} instantiated with various parameters,
four programs implementing the algorithms from~\cite{Jamieson2015TheAO}
and four data analysis programs 
from \hyperlink{https://github.com/scikit-learn/scikit-learn/tree/main/examples}{sklearn}~\cite{SklearnBenchmark} benchmark.
% 7 machine learning programs
% from \hyperlink{https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples}{tensorflow}~\cite{TensorflowBenchmark}
% and \hyperlink{https://github.com/pytorch/pytorch}{pytorch}~\cite{PytorchBenchmark}
% benchmarks.
% The 15 data analysis programs 
% from sklearn benchmark includes 12 programs with $O(n)$-adaptivity rounds
% and 3 programs with $O(n*m)$-adapvitiy rounds.
% % for the database classification.
% These $O(n)$-rounds adaptivity programs are
% the
% implementations of the decision tree, logistic regression, naive Gaussian inference classifiers
% with $O(n)$ fitting depth,
% and the grid search hyperparameter selecting algorithm for each classifier with 
% hyperparameter space of constant size $c$.
% The $O(n*m)$-rounds adaptivity programs are
% the implementations of the decision tree, logistic regression, naive Gaussian inference models equipped with one v.s. rest model with $O(n)$ fitting depth for classifying the dataset with $O(m)$ classes.
% These programs are evaluated for classifying a demography dataset from 
% the USA census database~\cite{CensusDatabase}.
{We use acronyms for these programs to describe the analyses they perform and fit the evaluation summary in a single table. We use LR for logistic regression, GD for gradient descent, mR for multiple round, DT for decisionTree, RQ for repeatedQuery, OVR for one-vs-rest, De for degree, Dim for dimension, Pair for pairwise. Similarly, we shorten the mechanisms: GS for Gaussian, DS for Data Split,
TS for ThresholdOut.  }

For each program, we show in Table~\ref{tb:adapt-generalization} the
generalization errors when running without a mechanism and running
with different mechanisms over uniformly generated training data.  The
average generalization error of each program is measured by
root-mean-square error (rmse).  The root-mean-square error without any
mechanism is shown in column ``None''. 
We mark the best rmse in red.
We mark in bold the rmse
produced by the mechanism chosen by {\THESYSTEM} using the following
heuristics.  According to Theorem~\ref{thm:nonadapt-adapt},\ref{thm:gaussiannoise},
\ref{thm:gaussiannoise2},
we compare the value of $\sqrt{\query \#}$ and
$\progA\sqrt{\log(\query \#)}$ and choose DataSplit if
$\sqrt{\query \#} \gg \progA\sqrt{\log(\query \#)}$ and Gaussian
mechanism if $\sqrt{\query \#} \ll \progA\sqrt{\log(\query \#)}$ and
Thresholdout mechanism if these two quantities are close. 
 It is worth
stressing that these are rough heuristics since we are omitting the
constants hidden in these theorems. We leave the problem to identify
the best heuristic to future work.

%% In short, all these data analysis programs behave overfitting when running over randomly generated data sets. 
%% To obtain good data analysis result with low generalization error,
%% one needs to run programs multiple times with different mechanisms.
%% This takes much longer time than just training a data analysis program with one run.
%% However, by using our tool in the first step, an analyst can directly equip the program with a chosen mechanism to get good
%% analysis results.

    According to our heuristics, our examples fall into three categories: 
    $\progA$ is much larger than $\query \#$, $\progA$ is close to  $\query \#$,
    and $\progA$ is much smaller than $\query \#$. 
    Since both $\progA$ and $\query \#$ are symbolic, the decision of our heuristics relies on 
    the instantiation of input parameters such as $k,m, n$. To better evaluate our heuristics, we present two different instantiations $k,m,n=10$ and $k,m, n =1000$ so that
    for the same example, our tool will choose different mechanisms.

We can see in Table~\ref{tb:adapt-generalization} that the mechanism
chosen by our heuristics (marked in bold) is the best in most cases.
In the setting of small parameters $k,m,n=10$, our heuristics
choose most of the times ThresholdOut. Exceptions are examples such as $\kw{DTOVR}$,
$\kw{LROVR}$
from \hyperlink{https://github.com/scikit-learn/scikit-learn/tree/main/examples}{sklearn}~\cite{SklearnBenchmark}
benchmark, and $\kw{RQ}$ from~\cite{Jamieson2015TheAO}, for which our tool
chooses the Gaussian mechanism.  In the setting of large parameters
$k,m,n=1000$, 
for most examples our tool chooses the Gaussian mechanism.
For $\kw{twoRounds}$, our heuristics suggest the DataSplit mechanism. For examples $\kw{lilUCB}$,
$\kw{nDPair}$ and $\kw{bestArm}$ from~\cite{Jamieson2015TheAO} within
the \emph{Guess and Check}~\cite{RogersRSSTW20} framework, our tool chooses the Thresholdout mechanism.

%% \remove{We first evaluate example programs from Table~\ref{tb:adapt-imp} as the baseline evaluation to show that our tool can choose the mechanism that performs best in reducing the generalization error as we claimed.
%% $\kw{twoRounds}$ is trained to classify a uniformly generated data set of size $n$ and $k$ features and a randomly selected label from $\{0, 1\}$. 
%% With only two adaptive rounds, by instantiating $k = 1000$ and $n = 1000$, this algorithm overfitted and produced the generalization error 
%% $0.050$.
%% Since $2* \sqrt{\log(1000)} \ll \sqrt{1000}$, {\THESYSTEM} chooses the DataSplit mechanism.
%% The evaluation result (\textbf{0.028}) shows that our choice is the best.
%% Then by instantiating $k = 10$, we see that $10 * \sqrt{\log(10)}$ is close to $\sqrt{10}$ and our tool chooses ThresholdOut, while Gaussian and ThresholdOut mechanism both perform well.}

%% \remove{The $2^{nd}$ to $5^{th}$ programs represent different algorithms for fitting a two-dimensional data set of size $n$ into a linear relation.
%%  $  \kw{ 3DimLRGD }$ and $  \kw{ 4DimLRGD }$ are the generalizations of LRGD into 3D and 4D data set of size $n$.
%%  The number of iterations (i.e., the fitting depth) is $k$, and {\THESYSTEM} estimates correctly the adaptivity rounds $k$ for these programs.
%%  By instantiating $k = 1000$ and $n = 1000$, we have
%% $1000* \sqrt{\log(1000)} \gg \sqrt{1000}$ which means that our tool chooses the Gaussian mechanism. When $k=10$ and $n=10$ instead, our tool chooses the ThresholdOut mechanism. }

%% \remove{The $2^{nd}$ to $5^{th}$ programs represent different algorithms for fitting a two-dimensional data set of size $n$ into a linear relation.
%% The number of iterations is $k$ and our tool identifies this as the  adaptivity  for these programs.
%% %  and chooses the Gaussian mechanism.
%% By instantiating $k = 1000$ and $n = 1000$, we have
%% $1000* \sqrt{\log(1000)} \gg \sqrt{1000}$ which means that our tool chooses the Gaussian mechanism. When $k=10$ and $n=10$ instead, our tool chooses the ThresholdOut mechanism. 
%% The evaluation results in Table~\ref{tb:adapt-generalization} show again that the chosen mechanism performs best among other mechanisms in reducing the generalization error.}

%% \remove{$  \kw{ 3DimLRGD }$ and $  \kw{ 4DimLRGD }$ are the generalizations of LRGD into 3D and 4D data set of size $n$.
%% %$  \kw{ 3DegreeLRGD }$ and $  \kw{ 4DegreeLRGD }$ are as well extending the logistic regression with gradient decedent
%% %algorithm into the fitting tasks of $3$ and $4$ degree polynomial relation on three-dimensional and four-dimensional data sets of size $n$ respectively.
%% The number of iterations (i.e., the fitting depth) is still $k$, and {\THESYSTEM} estimates correctly the adaptivity rounds $k$ for these two programs.
%% Instantiating $k$ and $n$ with $1000$ and $1000$,
%% %  the heuristics in Theorem~\ref{thm:gaussiannoise} and Theorem~\ref{thm:gaussiannoise2},
%% our tool chooses the Gaussian mechanism which still reduces rmse the most. When we instantiate $k$ and $n$ with $10$ and $10$, the ThresholdOut mechanism recommended by our tool also performs very well in Table~\ref{tb:adapt-generalization}. }
%% \remove{We have four data analyses {which are the implementation of algorithms} from~\cite{Jamieson2015TheAO} within the \emph{Guess and Check}~\cite{RogersRSSTW20} framework.
%% % is the
%% % repeated query subroutine algorithm with $n\times 2^n$ adaptivity rounds and $n\times 2^n$ query requests in total;
%% Programs $\kw{lilUCB}$ and $\kw{bestArm}$ are the algorithms to solve the best arm problem in the stochastic multi-armed bandit (MAB) setting
%% with $m$ total number of arms in order to identify the longest arm through sampling at most $n$ times.
%% Our tool identifies the number of sampling times $n$ is the adaptivity rounds.
%% %  with $n$ adaptivity rounds and $n$ query requests in total;
%% Programs $\kw{repeatedQuery}$ and $\kw{nDimPairwise}$ are the algorithms for ranking
%% a $1$-demensional dataset of size $n$ via querying the data $m$ times.
%% Our tool identifies the adaptvitiy w.r.t. the sampling times for these two programs as $m$ and $m \times 2^m$.
%% }
%% % These three algorithms are implemented into the \emph{Guess and Check}~\cite{RogersRSSTW20} framework 
%% % When running it, we are using the same mechanisms pre-defined in this framework as evaluating the first three examples.
%% \remove{By instantiating $n = 1000$ and $m = 1000$, these programs produce large generalization errors.
%% In this situation, $1000* \sqrt{\log(1000^2)}$ and $\sqrt{1000^2}$ are close to each other,
%% % According to the large adaptivity rounds and the query numbers, 
%% our tool chooses the Thresholdout mechanism.
%% \remove{Evaluation results in Table~\ref{tb:adapt-generalization} shows that both Thresholdout and Gaussian mechanism can reduce the rmse the most.}
%% When we look at a smaller $n$ and $m$ ($n,m=10$), because the query number is $m \times n$ and our $A_{est}$ is either $m$ or $n$ in these examples,
%% our tool still chooses ThresholdOut mechanism in three of the four examples \remove{in the \emph{Guess and Check} framework, $\kw{lilUCB}$, $\kw{nDimPairwise}$ and $\kw{bestArm}$} and our recommendation performs well. The only
%% exception is the $\kw{repeatedQuery}$ example, whose $A_{est}$ and query number are both quite big as $m \times 2^m$, and out tool
%% then chooses Gaussian mechanism, which does not perform well($6.01$).
%% }
%% \remove{For the four data analysis programs, 
%% from \hyperlink{https://github.com/scikit-learn/scikit-learn/tree/main/examples}{sklearn}~\cite{SklearnBenchmark} benchmark,
%% the first two programs, $\kw{decisionTree}$ and $\kw{logisticRegression}$ are
%% the
%% implementations of the decision tree, logistic regression classifiers
%% with $O(n)$ fitting depth,
%% and the grid search hyperparameter selects an algorithm for each classifier with 
%% hyperparameter space of constant size $c$.
%% The next two programs $\kw{decisionTreeOVR}$ and $\kw{logisticRegressionOVR}$ are
%% the implementations of the decision tree, logistic regression, equipped with one v.s. rest model with $k$ fitting depth for classifying the dataset with $m$ classes.
%% They are evaluated to classify a uniformly generated data set with $m$ randomly selected classes label. For these programs, we translate them manually into our syntax and evaluate their adaptivity.
%% By adaptivity analysis, our tool identified that the fitting depth is indeed the adaptivity rounds of these programs.
%% % The program $\kw{decisionTree}$ with only $5$ fitting depth has adaptivity rounds $5$,
%% % the Thresholdout mechanism performs best in terms of reducing the generalization error.
%% Programs $\kw{decisionTreeOVR}$ and $\kw{logisticRegressionOVR}$ 
%% have $k*m$ adaptivity rounds, by instantiating $k = 1000$ and $m = 1000$, {\THESYSTEM} chooses Gaussian mechanism, although it is not optimal for the decision tree example. While when we have a smaller $k$ and $m$ ($k,m=10$), the choice of our tool is reliable.
%% }

%% \remove{In summary, our experimental result shows that most of the time the knowledge of the adaptivity and the number of queries of a data analysis allow us to choose the best mechanism to  reduce the generalization error. We expect that this situation can be further improved by using more precise heuristic than the ones we use here. 
%% Due to the limit of space, more detials about the benchmarks and evaluation results can be found in the supplementary material.
%% }


