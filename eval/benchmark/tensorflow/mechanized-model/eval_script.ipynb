{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 12:40:44.609475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "keras = tf.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.from_tensor_slices([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from mechanism.mechanized_sequential import MechanizedSequential\n",
    "from mechanism.mechanized_sequential import Mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MEAN = 0.5\n",
    "EPOCH = 2\n",
    "POPULATION_SIZE = 10000\n",
    "TRAIN_DIM = 1000\n",
    "STEP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def initialize_with_str_seed(init_str):\n",
    "    \"\"\"\n",
    "    Initializes random number generator with seed corresponding to given input string init_str.\n",
    "    :param init_str: Initialization string according to which seed will be computed. Seed is the sum of the ASCII\n",
    "                     values of each character in init_str.\n",
    "    \"\"\"\n",
    "    rnd_val = 0\n",
    "    if init_str:\n",
    "        for c in init_str:\n",
    "            rnd_val += ord(c)\n",
    "    np.random.seed(rnd_val)\n",
    "\n",
    "def gen_data(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y\n",
    "\n",
    "def gen_valid(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    \n",
    "    n = int(n/10)\n",
    "    \n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x_train, y_train = gen_data(POPULATION_SIZE, TRAIN_DIM)\n",
    "x_valid, y_valid = gen_valid(POPULATION_SIZE, TRAIN_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_and_fit_model(model, train_set, epoch_num = EPOCH, eager = False):\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "    optimizer = keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "    model.compile(loss=keras.losses.Huber(),\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"mae\"],\n",
    "                run_eagerly = eager)\n",
    "\n",
    "    history = model.fit(train_set, epochs = epoch_num, callbacks=[lr_schedule])\n",
    "    return history\n",
    "\n",
    "def eval_model(train_size, epoch_num = EPOCH, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    ''' Compile and fit the empirical model as baseline'''\n",
    "    model = MechanizedSequential([\n",
    "        keras.layers.Conv1D(filters = 32,\n",
    "                            kernel_size = 5,\n",
    "                            strides = 1, \n",
    "                            padding = \"causal\",\n",
    "                            activation = \"relu\",\n",
    "                            input_shape = [None, 1]),\n",
    "        keras.layers.LSTM(32, return_sequences = True),\n",
    "        keras.layers.LSTM(32, return_sequences=True),\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Lambda(lambda x: x * 200)\n",
    "    ])    \n",
    "    batch_size = math.floor(train_size/STEP)\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train[:train_size], y_train[:train_size])).batch(batch_size)\n",
    "\n",
    "\n",
    "    if mechanism:\n",
    "        model.choose_mech(mechanism)\n",
    "        history = compile_and_fit_model(model, train_set, epoch_num, True)\n",
    "    else:\n",
    "        history = compile_and_fit_model(model, train_set, epoch_num, False)\n",
    "\n",
    "\n",
    "    ''' Validate the result'''\n",
    "    # x_valid, y_valid = gen_valid(POPULATION_SIZE, TRAIN_DIM)\n",
    "    # model.choose_mech(None)\n",
    "    predict = model.predict(x_valid)\n",
    "    \n",
    "    error = generalization_error(y_valid, predict)\n",
    "    return history, predict, error\n",
    "\n",
    "\n",
    "def generalization_error(true_val, predict_val):\n",
    "    error = keras.metrics.RootMeanSquaredError()\n",
    "    error.update_state(true_val, predict_val)\n",
    "    return error.result().numpy()\n",
    "\n",
    "\n",
    "def eval_multiple_rounds(train_size, stepped_epoch_num, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    history_list, predict_list, generalization_error_list = [], [], []\n",
    "    for r in stepped_epoch_num:\n",
    "        history, predict, error = eval_model(train_size = train_size, epoch_num = r, mechanism = mechanism)\n",
    "        history_list.append(history)\n",
    "        predict_list.append(predict)\n",
    "        generalization_error_list.append(error) \n",
    "\n",
    "    return history_list, predict_list, generalization_error_list\n",
    "\n",
    "def eval_const_rounds(stepped_train_size, epoch_num = EPOCH, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    history_list, predict_list, generalization_error_list = [], [], []\n",
    "    for n in stepped_train_size:\n",
    "        history, predict, error = eval_model(train_size = n, epoch_num = epoch_num, mechanism = mechanism)\n",
    "        history_list.append(history)\n",
    "        predict_list.append(predict)\n",
    "        generalization_error_list.append(error) \n",
    "\n",
    "    return history_list, predict_list, generalization_error_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' eval the empirical model as baseline'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Plot the Comparison of the Three Model\n",
    "'''\n",
    "def plot_error(rounds, generalization_error, mechanism):\n",
    "    plt.plot(rounds, generalization_error, label = mechanism)\n",
    "    plt.xlabel(\"Queries\")\n",
    "    plt.ylabel(\"RMSE (Generalization Error) for adaptive queries\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "max_query_num = 20\n",
    "\n",
    "stepped_query_num = range(math.floor(max_query_num/2), max_query_num, 10)\n",
    "\n",
    "''' eval the empirical model as baseline'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5/5 [==============================] - 21s 4s/step - loss: 13.3173 - mae: 13.8094 - lr: 1.0000e-08\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 20s 4s/step - loss: 13.2940 - mae: 13.7862 - lr: 1.1220e-08\n",
      "18/32 [===============>..............] - ETA: 23s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m baselin_history_list, baseline_predict_list, baseline_generalization_error_list \u001b[39m=\u001b[39m eval_const_rounds(stepped_query_num)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(baseline_generalization_error_list)\n",
      "Cell \u001b[0;32mIn[61], line 70\u001b[0m, in \u001b[0;36meval_const_rounds\u001b[0;34m(stepped_train_size, epoch_num, mechanism)\u001b[0m\n\u001b[1;32m     68\u001b[0m history_list, predict_list, generalization_error_list \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m stepped_train_size:\n\u001b[0;32m---> 70\u001b[0m     history, predict, error \u001b[39m=\u001b[39m eval_model(train_size \u001b[39m=\u001b[39;49m n, epoch_num \u001b[39m=\u001b[39;49m epoch_num, mechanism \u001b[39m=\u001b[39;49m mechanism)\n\u001b[1;32m     71\u001b[0m     history_list\u001b[39m.\u001b[39mappend(history)\n\u001b[1;32m     72\u001b[0m     predict_list\u001b[39m.\u001b[39mappend(predict)\n",
      "Cell \u001b[0;32mIn[61], line 45\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(train_size, epoch_num, mechanism)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39m# x_valid, y_valid = gen_valid(POPULATION_SIZE, TRAIN_DIM)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m model\u001b[39m.\u001b[39mchoose_mech(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 45\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_valid)\n\u001b[1;32m     47\u001b[0m error \u001b[39m=\u001b[39m generalization_error(y_valid, predict)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m history, predict, error\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:2350\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2349\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2350\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2351\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2352\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:2137\u001b[0m, in \u001b[0;36mModel.make_predict_function.<locals>.predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   2135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_function\u001b[39m(iterator):\n\u001b[1;32m   2136\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Runs an evaluation execution with a single step.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2137\u001b[0m     \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:2123\u001b[0m, in \u001b[0;36mModel.make_predict_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   2119\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2120\u001b[0m     )\n\u001b[1;32m   2122\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 2123\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   2124\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   2125\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2126\u001b[0m )\n\u001b[1;32m   2127\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:2111\u001b[0m, in \u001b[0;36mModel.make_predict_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 2111\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_step(data)\n\u001b[1;32m   2112\u001b[0m     \u001b[39m# Ensure counter is updated only if `test_step` succeeds.\u001b[39;00m\n\u001b[1;32m   2113\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:2079\u001b[0m, in \u001b[0;36mModel.predict_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The logic for one inference step.\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m \n\u001b[1;32m   2061\u001b[0m \u001b[39mThis method can be overridden to support custom inference logic.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[39m  `Model` on data.\u001b[39;00m\n\u001b[1;32m   2077\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2078\u001b[0m x, _, _ \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[0;32m-> 2079\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/training.py:561\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    559\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/sequential.py:413\u001b[0m, in \u001b[0;36mSequential.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m    412\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    415\u001b[0m outputs \u001b[39m=\u001b[39m inputs  \u001b[39m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    417\u001b[0m     \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[39m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[39m# the next layer.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/functional.py:511\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    494\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/functional.py:668\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 668\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    670\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    672\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[1;32m    673\u001b[0m ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/engine/base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1129\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1131\u001b[0m ):\n\u001b[0;32m-> 1132\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1135\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:743\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    733\u001b[0m         last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m gpu_lstm(\n\u001b[1;32m    734\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgpu_lstm_kwargs\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    737\u001b[0m         (\n\u001b[1;32m    738\u001b[0m             last_output,\n\u001b[1;32m    739\u001b[0m             outputs,\n\u001b[1;32m    740\u001b[0m             new_h,\n\u001b[1;32m    741\u001b[0m             new_c,\n\u001b[1;32m    742\u001b[0m             runtime,\n\u001b[0;32m--> 743\u001b[0m         ) \u001b[39m=\u001b[39m standard_lstm(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[1;32m    744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m     (\n\u001b[1;32m    746\u001b[0m         last_output,\n\u001b[1;32m    747\u001b[0m         outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m         runtime,\n\u001b[1;32m    751\u001b[0m     ) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:983\u001b[0m, in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    980\u001b[0m     h \u001b[39m=\u001b[39m o \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mtanh(c)\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m h, [h, c]\n\u001b[0;32m--> 983\u001b[0m last_output, outputs, new_states \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mrnn(\n\u001b[1;32m    984\u001b[0m     step,\n\u001b[1;32m    985\u001b[0m     inputs,\n\u001b[1;32m    986\u001b[0m     [init_h, init_c],\n\u001b[1;32m    987\u001b[0m     constants\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    988\u001b[0m     unroll\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    989\u001b[0m     time_major\u001b[39m=\u001b[39;49mtime_major,\n\u001b[1;32m    990\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    991\u001b[0m     go_backwards\u001b[39m=\u001b[39;49mgo_backwards,\n\u001b[1;32m    992\u001b[0m     input_length\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    993\u001b[0m         sequence_lengths \u001b[39mif\u001b[39;49;00m sequence_lengths \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m timesteps\n\u001b[1;32m    994\u001b[0m     ),\n\u001b[1;32m    995\u001b[0m     zero_output_for_mask\u001b[39m=\u001b[39;49mzero_output_for_mask,\n\u001b[1;32m    996\u001b[0m     return_all_outputs\u001b[39m=\u001b[39;49mreturn_sequences,\n\u001b[1;32m    997\u001b[0m )\n\u001b[1;32m    998\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    999\u001b[0m     last_output,\n\u001b[1;32m   1000\u001b[0m     outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     gru_lstm_utils\u001b[39m.\u001b[39mruntime(gru_lstm_utils\u001b[39m.\u001b[39mRUNTIME_CPU),\n\u001b[1;32m   1004\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/backend.py:5142\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   5137\u001b[0m         new_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   5138\u001b[0m             initial_states, flat_new_state\n\u001b[1;32m   5139\u001b[0m         )\n\u001b[1;32m   5140\u001b[0m         \u001b[39mreturn\u001b[39;00m (time \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, output_ta_t) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(new_states)\n\u001b[0;32m-> 5142\u001b[0m     final_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   5143\u001b[0m         body\u001b[39m=\u001b[39;49m_step,\n\u001b[1;32m   5144\u001b[0m         loop_vars\u001b[39m=\u001b[39;49m(time, output_ta) \u001b[39m+\u001b[39;49m states,\n\u001b[1;32m   5145\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mwhile_loop_kwargs,\n\u001b[1;32m   5146\u001b[0m     )\n\u001b[1;32m   5147\u001b[0m     new_states \u001b[39m=\u001b[39m final_outputs[\u001b[39m2\u001b[39m:]\n\u001b[1;32m   5149\u001b[0m output_ta \u001b[39m=\u001b[39m final_outputs[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2765\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2762\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2763\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2764\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2765\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[1;32m   2766\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2767\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/backend.py:5121\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   5119\u001b[0m current_input \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ta\u001b[39m.\u001b[39mread(time) \u001b[39mfor\u001b[39;00m ta \u001b[39min\u001b[39;00m input_ta)\n\u001b[1;32m   5120\u001b[0m current_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[0;32m-> 5121\u001b[0m output, new_states \u001b[39m=\u001b[39m step_function(\n\u001b[1;32m   5122\u001b[0m     current_input, \u001b[39mtuple\u001b[39;49m(states) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(constants)\n\u001b[1;32m   5123\u001b[0m )\n\u001b[1;32m   5124\u001b[0m flat_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(states)\n\u001b[1;32m   5125\u001b[0m flat_new_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(new_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/layers/rnn/lstm.py:970\u001b[0m, in \u001b[0;36mstandard_lstm.<locals>.step\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    967\u001b[0m c_tm1 \u001b[39m=\u001b[39m cell_states[\u001b[39m1\u001b[39m]  \u001b[39m# previous carry state\u001b[39;00m\n\u001b[1;32m    969\u001b[0m z \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mdot(cell_inputs, kernel)\n\u001b[0;32m--> 970\u001b[0m z \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mdot(h_tm1, recurrent_kernel)\n\u001b[1;32m    971\u001b[0m z \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mbias_add(z, bias)\n\u001b[1;32m    973\u001b[0m z0, z1, z2, z3 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msplit(z, \u001b[39m4\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/backend.py:2455\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   2453\u001b[0m     out \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39msparse_dense_matmul(x, y)\n\u001b[1;32m   2454\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2455\u001b[0m     out \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(x, y)\n\u001b[1;32m   2456\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:3714\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3711\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39mbatch_mat_mul_v3(\n\u001b[1;32m   3712\u001b[0m       a, b, adj_x\u001b[39m=\u001b[39madjoint_a, adj_y\u001b[39m=\u001b[39madjoint_b, Tout\u001b[39m=\u001b[39moutput_type, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m   3713\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3714\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[1;32m   3715\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py:6014\u001b[0m, in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6012\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   6013\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 6014\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   6015\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMatMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, a, b, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_a\u001b[39;49m\u001b[39m\"\u001b[39;49m, transpose_a, \u001b[39m\"\u001b[39;49m\u001b[39mtranspose_b\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   6016\u001b[0m       transpose_b)\n\u001b[1;32m   6017\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   6018\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "baselin_history_list, baseline_predict_list, baseline_generalization_error_list = eval_const_rounds(stepped_query_num)\n",
    "print(baseline_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x144f674c0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/usr/local/lib/python3.10/site-packages/keras/backend.py\", line 5132, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x144f674c0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/usr/local/lib/python3.10/site-packages/keras/backend.py\", line 5132, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 20s 4s/step - loss: 15.2770 - mae: 15.7767 - lr: 1.0000e-08\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 24s 4s/step - loss: 15.2475 - mae: 15.7472 - lr: 1.1220e-08\n",
      "17/32 [==============>...............] - ETA: 27s"
     ]
    }
   ],
   "source": [
    "gaussian_history_list, gaussian_predict_list, gaussian_generalization_error_list = eval_const_rounds(stepped_query_num, mechanism = Mechanism(Mechanism.MechanismType.GAUSSIAN, sigma = 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Compile and fit the gaussian model'''\n",
    "gaussian_history_list, gaussian_predict_list, gaussian_generalization_error_list = eval_multiple_rounds(stepped_rounds, mechanism = Mechanism.MechanismType.GAUSSIAN, sigma = 0.03)\n",
    "print(gaussian_generalization_error_list)\n",
    "\n",
    "# gaussian_generalization_error_list = [65.59238, 53.909763, 41.66362, 32.519978, 26.558846]\n",
    "\n",
    "''' Compile and fit the threshold out model'''\n",
    "threshold_history_list, threshold_predict_list, threshold_generalization_error_list = eval_multiple_rounds(stepped_rounds, mechanism = Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.4, threshold = 0.5)\n",
    "print(threshold_generalization_error_list)\n",
    "\n",
    "# threshold_generalization_error_list = [15.81994, 19.699022, 23.081583, 25.196918, 26.020424]\n",
    "\n",
    "\"\"\" plot the generalization error \"\"\"\n",
    "plt.figure()\n",
    "plot_error(stepped_rounds, baseline_generalization_error_list, \"Baseline\")\n",
    "plot_error(stepped_rounds, gaussian_generalization_error_list, \"Gaussian - AdaptFun\")\n",
    "plot_error(stepped_rounds, threshold_generalization_error_list, \"Threshold\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
