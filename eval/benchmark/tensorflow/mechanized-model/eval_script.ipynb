{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 12:40:44.609475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "keras = tf.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.from_tensor_slices([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from mechanism.mechanized_sequential import MechanizedSequential\n",
    "from mechanism.mechanized_sequential import Mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MEAN = 0.5\n",
    "EPOCH = 2\n",
    "POPULATION_SIZE = 10000\n",
    "TRAIN_DIM = 1000\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def initialize_with_str_seed(init_str):\n",
    "    \"\"\"\n",
    "    Initializes random number generator with seed corresponding to given input string init_str.\n",
    "    :param init_str: Initialization string according to which seed will be computed. Seed is the sum of the ASCII\n",
    "                     values of each character in init_str.\n",
    "    \"\"\"\n",
    "    rnd_val = 0\n",
    "    if init_str:\n",
    "        for c in init_str:\n",
    "            rnd_val += ord(c)\n",
    "    np.random.seed(rnd_val)\n",
    "\n",
    "def gen_data(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y\n",
    "\n",
    "def gen_valid(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    \n",
    "    n = int(n/10)\n",
    "    \n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x_train, y_train = gen_data(POPULATION_SIZE, TRAIN_DIM)\n",
    "x_valid, y_valid = gen_data(int(POPULATION_SIZE/500), TRAIN_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_and_fit_model(model, train_set, epoch_num = EPOCH, eager = False):\n",
    "    keras.backend.clear_session()\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "    optimizer = keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "    model.compile(loss=keras.losses.Huber(),\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"mae\"],\n",
    "                run_eagerly = eager)\n",
    "\n",
    "    history = model.fit(train_set, epochs = epoch_num, callbacks=[lr_schedule])\n",
    "    return history\n",
    "\n",
    "def eval_model(train_size, epoch_num = EPOCH, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    ''' Compile and fit the empirical model as baseline'''\n",
    "    model = MechanizedSequential([\n",
    "        keras.layers.Conv1D(filters = 32,\n",
    "                            kernel_size = 5,\n",
    "                            strides = 1, \n",
    "                            padding = \"causal\",\n",
    "                            activation = \"relu\",\n",
    "                            input_shape = [None, 1]),\n",
    "        keras.layers.LSTM(32, return_sequences = True),\n",
    "        keras.layers.LSTM(32, return_sequences=True),\n",
    "        keras.layers.Dense(1),\n",
    "        keras.layers.Lambda(lambda x: x * 200)\n",
    "    ])    \n",
    "    batch_size = math.floor(train_size/STEP)\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train[:train_size], y_train[:train_size])).batch(batch_size)\n",
    "\n",
    "\n",
    "    if mechanism:\n",
    "        model.choose_mech(mechanism)\n",
    "        history = compile_and_fit_model(model, train_set, epoch_num, True)\n",
    "    else:\n",
    "        history = compile_and_fit_model(model, train_set, epoch_num, False)\n",
    "\n",
    "\n",
    "    ''' Validate the result'''\n",
    "    # x_valid, y_valid = gen_valid(POPULATION_SIZE, TRAIN_DIM)\n",
    "    # model.choose_mech(None)\n",
    "    predict = model.predict(x_valid)\n",
    "    \n",
    "    error = generalization_error(y_valid, predict)\n",
    "    return history, predict, error\n",
    "\n",
    "\n",
    "def generalization_error(true_val, predict_val):\n",
    "    error = keras.metrics.RootMeanSquaredError()\n",
    "    error.update_state(true_val, predict_val)\n",
    "    return error.result().numpy()\n",
    "\n",
    "\n",
    "def eval_multiple_rounds(train_size, stepped_epoch_num, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    history_list, predict_list, generalization_error_list = [], [], []\n",
    "    for r in stepped_epoch_num:\n",
    "        history, predict, error = eval_model(train_size = train_size, epoch_num = r, mechanism = mechanism)\n",
    "        history_list.append(history)\n",
    "        predict_list.append(predict)\n",
    "        generalization_error_list.append(error) \n",
    "\n",
    "    return history_list, predict_list, generalization_error_list\n",
    "\n",
    "def eval_const_rounds(stepped_train_size, epoch_num = EPOCH, mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "    history_list, predict_list, generalization_error_list = [], [], []\n",
    "    for n in stepped_train_size:\n",
    "        history, predict, error = eval_model(train_size = n, epoch_num = epoch_num, mechanism = mechanism)\n",
    "        history_list.append(history)\n",
    "        predict_list.append(predict)\n",
    "        generalization_error_list.append(error) \n",
    "\n",
    "    return history_list, predict_list, generalization_error_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' eval the empirical model as baseline'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Plot the Comparison of the Three Model\n",
    "'''\n",
    "def plot_error(rounds, generalization_error, mechanism):\n",
    "    plt.plot(rounds, generalization_error, label = mechanism)\n",
    "    plt.xlabel(\"Queries\")\n",
    "    plt.ylabel(\"RMSE (Generalization Error) for adaptive queries\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_query_num = 10\n",
    "\n",
    "stepped_query_num = range(math.floor(max_query_num/2), max_query_num, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.0537 - mae: 12.5505 - lr: 1.0000e-08\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12.0510 - mae: 12.5478 - lr: 1.1220e-08\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[13.719473]\n"
     ]
    }
   ],
   "source": [
    "''' eval the empirical model as baseline'''\n",
    "baselin_history_list, baseline_predict_list, baseline_generalization_error_list = eval_const_rounds(stepped_query_num)\n",
    "print(baseline_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.2028 - mae: 5.6872 - lr: 1.0000e-08\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5.2021 - mae: 5.6865 - lr: 1.1220e-08\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "''' Compile and fit the gaussian model'''\n",
    "gaussian_history_list, gaussian_predict_list, gaussian_generalization_error_list = eval_const_rounds(stepped_query_num, mechanism = Mechanism(Mechanism.MechanismType.GAUSSIAN, sigma = 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.6889744]\n"
     ]
    }
   ],
   "source": [
    "print(gaussian_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2.2100 - mae: 2.6720 - lr: 1.0000e-08\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 5s 5s/step - loss: 2.2099 - mae: 2.6719 - lr: 1.1220e-08\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "[3.270109]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' Compile and fit the threshold out model'''\n",
    "threshold_history_list, threshold_predict_list, threshold_generalization_error_list = eval_const_rounds(stepped_train_size = stepped_query_num, mechanism = Mechanism(Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.4, threshold = 0.5))\n",
    "print(threshold_generalization_error_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" plot the generalization error \"\"\"\n",
    "plt.figure()\n",
    "plot_error(stepped_query_num, baseline_generalization_error_list, \"Baseline\")\n",
    "plot_error(stepped_query_num, gaussian_generalization_error_list, \"Gaussian\")\n",
    "plot_error(stepped_query_num, threshold_generalization_error_list, \"Threshold - AdaptFun\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_query_num = 10\n",
    "max_rounds = 20\n",
    "stepped_rounds = range(math.floor(max_rounds/2), max_rounds, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.5778 - mae: 8.0772 - lr: 1.0000e-08\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5762 - mae: 8.0756 - lr: 1.1220e-08\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5730 - mae: 8.0724 - lr: 1.2589e-08\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5680 - mae: 8.0674 - lr: 1.4125e-08\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5613 - mae: 8.0607 - lr: 1.5849e-08\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5527 - mae: 8.0521 - lr: 1.7783e-08\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5422 - mae: 8.0415 - lr: 1.9953e-08\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5294 - mae: 8.0288 - lr: 2.2387e-08\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.5144 - mae: 8.0138 - lr: 2.5119e-08\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7.4968 - mae: 7.9962 - lr: 2.8184e-08\n",
      "32/32 [==============================] - 60s 2s/step\n",
      "[8.380077]\n"
     ]
    }
   ],
   "source": [
    "''' eval the empirical model as baseline'''\n",
    "baselin_history_list, baseline_predict_list, baseline_generalization_error_list = eval_multiple_rounds(max_query_num, stepped_rounds)\n",
    "print(baseline_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4830 - mae: 10.9826 - lr: 1.0000e-08\n",
      "Epoch 2/10\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x16d5d3c70>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/usr/local/lib/python3.10/site-packages/keras/backend.py\", line 5132, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x16d5d3c70>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/usr/local/lib/python3.10/site-packages/keras/backend.py\", line 5132, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/usr/local/lib/python3.10/site-packages/tensorflow/python/util/tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 10.4815 - mae: 10.9812 - lr: 1.1220e-08\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4785 - mae: 10.9782 - lr: 1.2589e-08\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4740 - mae: 10.9736 - lr: 1.4125e-08\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4678 - mae: 10.9675 - lr: 1.5849e-08\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4600 - mae: 10.9596 - lr: 1.7783e-08\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.4502 - mae: 10.9499 - lr: 1.9953e-08\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4386 - mae: 10.9382 - lr: 2.2387e-08\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10.4247 - mae: 10.9244 - lr: 2.5119e-08\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.4086 - mae: 10.9083 - lr: 2.8184e-08\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "''' Compile and fit the gaussian model'''\n",
    "gaussian_history_list, gaussian_predict_list, gaussian_generalization_error_list = eval_multiple_rounds(max_query_num, stepped_rounds, mechanism = Mechanism(Mechanism.MechanismType.GAUSSIAN, sigma = 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.296159]\n"
     ]
    }
   ],
   "source": [
    "print(gaussian_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Compile and fit the threshold out model'''\n",
    "threshold_history_list, threshold_predict_list, threshold_generalization_error_list = eval_multiple_rounds(max_query_num, stepped_rounds, mechanism = Mechanism(Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.4, threshold = 0.5))\n",
    "print(threshold_generalization_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# threshold_generalization_error_list = [15.81994, 19.699022, 23.081583, 25.196918, 26.020424]\n",
    "\n",
    "\"\"\" plot the generalization error \"\"\"\n",
    "plt.figure()\n",
    "plot_error(stepped_query_num, baseline_generalization_error_list, \"Baseline\")\n",
    "plot_error(stepped_query_num, gaussian_generalization_error_list, \"Gaussian\")\n",
    "plot_error(stepped_query_num, threshold_generalization_error_list, \"Threshold - AdaptFun\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
