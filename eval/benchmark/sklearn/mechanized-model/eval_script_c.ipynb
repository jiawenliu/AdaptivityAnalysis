{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, mean_squared_error, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basic preprocessing\n",
    "def preprocess(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Discard identifiers, style information, timestamps\n",
    "    df_new = df_new[df_new.columns.difference(['image', 'style', 'reviewTime', \n",
    "                                               'reviewerID', 'asin', 'reviewerName', 'unixReviewTime'])]\n",
    "\n",
    "    # Turn category into binary features\n",
    "    for cat in df_new.category.unique():\n",
    "        df_new[cat] = df_new['category'] == cat\n",
    "\n",
    "    # Drop category column\n",
    "    df_new.drop(columns=['category'], inplace=True)\n",
    "\n",
    "    # NaN vote is 0 users found helpful\n",
    "    df_new.vote.fillna(0, inplace=True)\n",
    "    \n",
    "    # Turn vote into binary feature\n",
    "    df_new.vote = df_new.vote > 0\n",
    "    # df_new.vote.clip(0, 10)\n",
    "    # df_new.vote = df_new.vote / 10\n",
    "\n",
    "    # NaN summary is empty summary\n",
    "    df_new.summary.fillna('', inplace=True)\n",
    "\n",
    "    # Turn Booleans into binary variables\n",
    "    df_new.replace({False: 0, True: 1}, inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# Remove 'overall' column and add cutoff column applying cutoff\n",
    "def apply_cutoff(df, cutoff):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # Apply cutoff\n",
    "    cut = df['overall'] > cutoff\n",
    "    df_new['cutoff'] = cut\n",
    "\n",
    "    # Drop overall and category\n",
    "    df_new.drop(columns=['overall'], inplace=True)\n",
    "    \n",
    "    # Turn Booleans into binary variables\n",
    "    df_new.replace({False: 0, True: 1}, inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "def apply_tfidf(df, review_vectorizer, summary_vectorizer):\n",
    "    review_matrix = pd.DataFrame(data=review_vectorizer.transform(df.reviewText).toarray(), columns='R_' + review_vectorizer.get_feature_names_out())\n",
    "    summary_matrix = pd.DataFrame(data=summary_vectorizer.transform(df.summary).toarray(), columns='S_' + summary_vectorizer.get_feature_names_out())\n",
    "    df_new = pd.concat([df, review_matrix, summary_matrix], axis=1)\n",
    "    df_new.drop(columns=['summary', 'reviewText'], inplace=True)\n",
    "    return df_new\n",
    "\n",
    "\n",
    "# Processing the data - I\n",
    "# Preprocessing of training data\n",
    "def load_and_process_data():\n",
    "    training_df = pd.read_csv('../data/Training.csv')\n",
    "    test_df = pd.read_csv('../data/Test.csv')\n",
    "\n",
    "    proc_training_df = apply_cutoff(preprocess(training_df), 1)\n",
    "\n",
    "    # Set cutoff to be the label; define data_x and y accordingly\n",
    "    data_x = proc_training_df.drop('cutoff', axis=1)\n",
    "    data_y = proc_training_df['cutoff']\n",
    "\n",
    "    # Fit TF-IDF vectorizer for 'reviewText' and 'summary' features, creating max. 11500 features.\n",
    "    r_vectorizer = TfidfVectorizer(max_features=11500, stop_words='english', ngram_range=(1, 3))\n",
    "    s_vectorizer = TfidfVectorizer(max_features=11500, stop_words='english', ngram_range=(1, 3))\n",
    "    r_vectorizer.fit(data_x.reviewText)\n",
    "    s_vectorizer.fit(data_x.summary)\n",
    "\n",
    "    # Apply TF-IDF vectorization \n",
    "    data_x = apply_tfidf(data_x, r_vectorizer, s_vectorizer)\n",
    "\n",
    "    # Apply robust scaling\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "    data_x = pd.DataFrame(scaler.fit_transform(data_x), columns=data_x.columns, index=data_x.index)\n",
    "\n",
    "    # Let us reduce the number of features by eliminating the statistically least correlated ones.\n",
    "    relcols = data_x.columns[abs(data_x.corrwith(data_y)) > 0.01]\n",
    "\n",
    "\n",
    "    # We will go with these columns.\n",
    "    data_x = data_x[relcols]\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "def create_splits(data_x, data_y, n_splits):\n",
    "    # 5-fold cross validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    splits = []\n",
    "    for train_idx, val_idx in kf.split(data_x, data_y):\n",
    "        # Apply split\n",
    "        x_train, x_val = data_x.iloc[train_idx], data_x.iloc[val_idx]\n",
    "        y_train, y_val = data_y.iloc[train_idx], data_y.iloc[val_idx]\n",
    "        \n",
    "        # Reset indices\n",
    "        x_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        x_val.reset_index(drop=True, inplace=True)\n",
    "        y_val.reset_index(drop=True, inplace=True)\n",
    "        splits.append((x_train, x_val, y_train, y_val))\n",
    "    return splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_DATA, Y_DATA = load_and_process_data()\n",
    "\n",
    "# test_splits = create_splits(X_DATA, Y_DATA, 5)\n",
    "\n",
    "# print(len(test_splits[0][1]), len(X_DATA))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and create the population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_MEAN = 0.5\n",
    "EPOCH = 2\n",
    "POPULATION_SIZE = 500000\n",
    "TRAIN_DIM = 100\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialize_with_str_seed(init_str):\n",
    "    \"\"\"\n",
    "    Initializes random number generator with seed corresponding to given input string init_str.\n",
    "    :param init_str: Initialization string according to which seed will be computed. Seed is the sum of the ASCII\n",
    "                     values of each character in init_str.\n",
    "    \"\"\"\n",
    "    rnd_val = 0\n",
    "    if init_str:\n",
    "        for c in init_str:\n",
    "            rnd_val += ord(c)\n",
    "    np.random.seed(rnd_val)\n",
    "\n",
    "def gen_data(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y\n",
    "\n",
    "def gen_valid(n, d, seed = None):\n",
    "    if seed:\n",
    "        initialize_with_str_seed(seed)\n",
    "    \n",
    "    n = int(n/10)\n",
    "    \n",
    "    p = (1.0 + np.sqrt(max(2 * Q_MEAN - 1, 1 - 2 * Q_MEAN))) / 2 \n",
    "    data = np.random.choice([-1, 1], (n, d), p=[1 -p, p])\n",
    "    data_y = np.random.choice([0, 1], n, p=[1 -p, p])\n",
    "    return data, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_population, y_population = gen_data(POPULATION_SIZE, TRAIN_DIM)\n",
    "x_valid, y_valid = gen_data(int(POPULATION_SIZE/500), TRAIN_DIM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from mechanism.mechanized_models import Mechanism\n",
    "from mechanism.mechanized_models import MechanizedGaussianNB, MechanizedLogisticRegression, MechanizedOneVSRest, MechanizedDecisionTree\n",
    "from mechanism.mechanized_models import MechanizedGridSearchCV\n",
    "\n",
    "def hyper_parameter(splits):\n",
    "    x_train, x_val, y_train, y_val = splits[0]\n",
    "    estimator = MechanizedLogisticRegression(max_iter=1500)\n",
    "    estimator.choose_mechanism(Mechanism.GAUSSIAN)\n",
    "    gs_cls = MechanizedOneVSRest(estimator = estimator)\n",
    "    gs_cls.choose_mechanism(Mechanism.GAUSSIAN)\n",
    "\n",
    "    params_LR = {'estimator__C': np.logspace(-0.2, 0.7, num = 10)}\n",
    "    gs_LR = GridSearchCV(estimator=gs_cls, param_grid=params_LR, cv = 2, verbose=2, scoring='f1_macro')\n",
    "    gs_LR.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "BEST_C = 1.5848931924611134\n",
    "'''\n",
    "C=1.5848931924611134, max_iter=1500\n",
    "'''\n",
    "\n",
    "def generalization_error(true_val, pred_val):\n",
    "    return np.sqrt(abs(mean_squared_error(true_val, pred_val) - Q_MEAN))\n",
    "\n",
    "\n",
    "\n",
    "def eval_multiple_rounds(stepped_rounds, mechanism, non_adaptive_num):\n",
    "    generalization_error_list = []\n",
    "    for r in stepped_rounds:\n",
    "        estimator = MechanizedLogisticRegression(C = BEST_C, max_iter = r, mechanism = mechanism, solver = 'sag')\n",
    "        generalization_error_list.append(eval(non_adaptive_num, estimator, mechanism))\n",
    "    return generalization_error_list\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation the O(1) adaptivity program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_const(round, train_size, mechanism):\n",
    "    # f1_scores, acc_scores, models = [], [], [], [], []\n",
    "    x_train, y_train = x_population[:train_size], y_population[:train_size]    \n",
    "    model = MechanizedLogisticRegression(C = BEST_C, max_iter = round, mechanism = mechanism)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    # Predict\n",
    "    y_pred = model.predict(x_valid)\n",
    "\n",
    "    return generalization_error(y_valid, y_pred)\n",
    "\n",
    "def eval_const_rounds(round, mechanism, stepped_non_adaptive_num):\n",
    "    generalization_error_list = []\n",
    "    for train_size in stepped_non_adaptive_num:\n",
    "        generalization_error_list.append(eval_const(round, train_size, mechanism))\n",
    "    return generalization_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepped_non_adaptive_num = range(1000, 100000, 20)\n",
    "round = 5\n",
    "stepped_non_adaptive_num = range(1000, 1010, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baseline_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.NONE), stepped_non_adaptive_num)\n",
    "# baseline_generalization_error_list = [0.47190818773552584, 0.473107228502912, 0.473792394655704, 0.47070914696813976, 0.4659129838985954, 0.4720794792737239, 0.47447756080849607, 0.473107228502912, 0.4775608084960603, 0.47619047619047616, 0.4712230215827338, 0.47447756080849607, 0.47567660157588215, 0.473792394655704, 0.47533401849948614]\n",
    "print(np.mean(baseline_generalization_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.GAUSSIAN, sigma = 0.5), stepped_non_adaptive_num)\n",
    "# gaussian_generalization_error_list = [0.3984241178485783, 0.4035628639945187, 0.39482699554642003, 0.3977389516957862, 0.3977389516957862, 0.3917437478588558, 0.3975676601575882, 0.39585474477560806, 0.38866050017129156, 0.3970537855429942, 0.39568345323741005, 0.3857485440219253, 0.38506337786913325, 0.39157245632065774, 0.3871188763275094]\n",
    "\n",
    "print(gaussian_generalization_error_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.7, threshold = 0.8), stepped_non_adaptive_num)\n",
    "# gaussian_generalization_error_list = [0.3984241178485783, 0.4035628639945187, 0.39482699554642003, 0.3977389516957862, 0.3977389516957862, 0.3917437478588558, 0.3975676601575882, 0.39585474477560806, 0.38866050017129156, 0.3970537855429942, 0.39568345323741005, 0.3857485440219253, 0.38506337786913325, 0.39157245632065774, 0.3871188763275094]\n",
    "\n",
    "print(threshold_generalization_error_list)\n",
    "print(np.mean(threshold_generalization_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.DATASPLIT), stepped_non_adaptive_num)\n",
    "print(np.mean(data_split_generalization_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.GAUSSIAN, sigma = 0.5), stepped_non_adaptive_num)\n",
    "print(np.mean(gaussian_generalization_error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MechanizedLogisticRegression(LogisticRegression):\n",
    "\n",
    "    def __init__(self, penalty=\"l2\", *, dual=False, tol=0.0001, C=1, \n",
    "                 fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "                 random_state=None, solver=\"lbfgs\", max_iter=100, multi_class=\"auto\", \n",
    "                 verbose=0, warm_start=False, n_jobs=None, \n",
    "                 l1_ratio=None,\n",
    "                 mechanism = Mechanism(Mechanism.MechanismType.NONE)):\n",
    "        super(MechanizedLogisticRegression, self).__init__(penalty, dual=dual, \n",
    "                                                           tol = tol, C = C, fit_intercept = fit_intercept, \n",
    "                                                           intercept_scaling = intercept_scaling,\n",
    "                                                           class_weight = class_weight, \n",
    "                                                           random_state = random_state, \n",
    "                                                           solver = solver, \n",
    "                                                           max_iter = max_iter, \n",
    "                                                           multi_class = multi_class, \n",
    "                                                           verbose = verbose, \n",
    "                                                           warm_start = warm_start, \n",
    "                                                           n_jobs = n_jobs, \n",
    "                                                           l1_ratio = l1_ratio)\n",
    "        self.mechanism = mechanism\n",
    "\n",
    "    def fit_data_split(self, x_train, y_train):\n",
    "        size = len(x_train)\n",
    "        hold_size, train_size = int(size  * (self.mechanism.hold_frac)), int(size  * (1.0 - self.mechanism.hold_frac))\n",
    "        x_train, y_train, x_hold, y_hold = x_train[hold_size:], y_train[hold_size:], x_train[:hold_size], y_train[:hold_size]\n",
    "        train_result = super(MechanizedLogisticRegression, self).fit(x_train, y_train)\n",
    "        train_pred = train_result.predict(x_train)\n",
    "        hold_result = super(MechanizedLogisticRegression, self).fit(x_hold, y_hold)\n",
    "        hold_pred = hold_result.predict(x_hold)\n",
    "        if abs(accuracy_score(train_pred, y_train) - accuracy_score(hold_pred, y_hold)) >= self.mechanism.noisy_thresh + np.random.laplace(0, 4 * self.mechanism.sigma):\n",
    "            self.mechanism.noisy_thresh = self.mechanism.threshold + np.random.laplace(0, 2 * self.mechanism.sigma)\n",
    "            x_noise =  np.random.laplace(0, 2 * self.mechanism.sigma, x_hold.shape)\n",
    "            return super(MechanizedLogisticRegression, self).fit(x_hold + x_noise, y_hold)\n",
    "        else:\n",
    "            return train_result\n",
    "\n",
    "    def fit_threshold(self, x_train, y_train):\n",
    "        size = len(x_train)\n",
    "        hold_size, train_size = int(size  * (self.mechanism.hold_frac)), int(size  * (1.0 - self.mechanism.hold_frac))\n",
    "        x_train, y_train, x_hold, y_hold = x_train[hold_size:], y_train[hold_size:], x_train[:hold_size], y_train[:hold_size]\n",
    "        train_result = super(MechanizedLogisticRegression, self).fit(x_train, y_train)\n",
    "        train_pred = train_result.predict(x_train)\n",
    "        hold_result = super(MechanizedLogisticRegression, self).fit(x_hold, y_hold)\n",
    "        hold_pred = hold_result.predict(x_hold)\n",
    "        if abs(accuracy_score(train_pred, y_train) - accuracy_score(hold_pred, y_hold)) >= self.mechanism.noisy_thresh + np.random.laplace(0, 4 * self.mechanism.sigma):\n",
    "            self.mechanism.noisy_thresh = self.mechanism.threshold + np.random.laplace(0, 2 * self.mechanism.sigma)\n",
    "            x_noise =  np.random.laplace(0, 2 * self.mechanism.sigma, x_hold.shape)\n",
    "            return super(MechanizedLogisticRegression, self).fit(x_hold + x_noise, y_hold)\n",
    "        else:\n",
    "            return train_result\n",
    "\n",
    "\n",
    "    def fit_gaussian(self, x_train, y_train):\n",
    "        x_noise = np.random.normal(0, self.mechanism.sigma, x_train.shape) \n",
    "        noised_x = x_train + x_noise        \n",
    "        \n",
    "        ################ Gaussian Noise Added to Labels ################\n",
    "        y_noise = np.random.normal(0, self.mechanism.sigma, y_train.shape) \n",
    "        noised_y = y_train + y_noise\n",
    "\n",
    "        noised_y = (map(lambda x : 0 if x < 0 else 1, noised_y))\n",
    "        print( y_train + y_noise, noised_y)\n",
    "\n",
    "\n",
    "        result = super(MechanizedLogisticRegression, self).fit(noised_x, noised_y)\n",
    "        if isinstance(result, LogisticRegression):\n",
    "            return self\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        if self.mechanism.mechanism_type ==  Mechanism.MechanismType.NONE:\n",
    "            print(\"in Baseline Logistic Regression\")\n",
    "            result = super(MechanizedLogisticRegression, self).fit(x_train, y_train)\n",
    "            if isinstance(result, LogisticRegression):\n",
    "                return self\n",
    "            else:\n",
    "                return result\n",
    "        elif self.mechanism.mechanism_type ==  Mechanism.MechanismType.GAUSSIAN:\n",
    "            print(\"in Gaussian Mechanized Logistic Regression\")\n",
    "            return self.fit_gaussian(x_train, y_train)\n",
    "        \n",
    "        elif self.mechanism.mechanism_type ==  Mechanism.MechanismType.THRESHOLD:\n",
    "            print(\"in Threshold Mechanized Logistic Regression\")\n",
    "            return self.fit_threshold(x_train, y_train)\n",
    "        else:\n",
    "            result = super(MechanizedLogisticRegression, self).fit(x_train, y_train)\n",
    "            if isinstance(result, LogisticRegression):\n",
    "                return self\n",
    "            else:\n",
    "                return result\n",
    "           \n",
    "    def choose_mechanism(self, mech):\n",
    "        self.mechanism = mech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Gaussian Mechanized Logistic Regression\n",
      "[-1.11283209e-02  1.01340991e+00  9.72771926e-01  1.01026929e+00\n",
      " -1.77416899e-02 -3.93874303e-02  2.78072718e-02 -9.36532287e-03\n",
      "  1.88443142e-02 -3.89553733e-03  6.43627306e-03 -4.25852500e-02\n",
      " -2.83779061e-02 -3.13361221e-02  2.73668044e-02 -1.75324766e-02\n",
      " -3.18778572e-02  9.89953440e-01  9.90800158e-01  1.80311251e-02\n",
      "  1.04048547e+00  7.33315158e-02  9.74419738e-01  5.09845250e-02\n",
      "  9.30166951e-01 -1.70295273e-02  1.01546813e+00  1.00572311e+00\n",
      "  1.03332437e+00  6.60577845e-04  9.93589281e-01 -4.36127381e-03\n",
      " -4.77512271e-02  9.28881176e-01 -2.14466495e-04  2.22937136e-02\n",
      "  9.39982460e-01  1.05556651e+00 -2.48163165e-02  9.93242129e-01\n",
      "  9.07524176e-03  6.34377248e-02  4.73468270e-02  4.21363059e-02\n",
      "  1.03576252e+00 -4.82956486e-02  9.76014671e-01  9.59106937e-01\n",
      "  1.00809923e+00  1.89961825e-02  3.96658885e-02  3.87969197e-02\n",
      " -2.92738449e-02 -1.63973819e-02  1.46313034e-02  1.44262571e-02\n",
      "  1.03968554e+00  9.90703034e-01  9.43636972e-01  1.04067726e+00\n",
      "  9.83776887e-01  9.84599436e-01  1.02255914e+00 -3.33587658e-02\n",
      "  4.26484722e-02  2.52065017e-02  1.00092156e+00 -6.41117348e-02\n",
      "  1.36254205e-02  5.08755907e-03  1.14248931e-03  1.00179175e+00\n",
      "  2.80436906e-02 -7.46877329e-03  2.45650658e-02  2.64305570e-02\n",
      " -1.52169388e-02 -3.70600687e-02 -4.47528054e-02  1.06364053e+00\n",
      "  1.01124288e+00  4.22602208e-02  1.03825827e+00  9.58506376e-01\n",
      "  9.75284049e-01  9.82776483e-01  9.83296370e-01  3.39524443e-03\n",
      "  2.91128192e-02 -5.82082625e-03  1.28650339e-02  2.67113903e-02\n",
      " -3.74807463e-02  1.00834166e+00 -6.83164486e-03  9.81974620e-01\n",
      " -1.21137273e-02  1.01188285e+00  9.69900166e-03  2.09831764e-02\n",
      "  1.01167285e+00  1.00571338e+00  6.67097170e-04 -3.27894571e-02\n",
      "  1.55184297e-03  1.03043478e+00  1.35544972e-02  9.89386348e-01\n",
      "  1.04278845e+00  1.00104411e+00  1.02617503e+00 -2.49973204e-02\n",
      "  9.60390060e-01  1.00956600e+00 -3.89883660e-02  9.50468845e-01\n",
      "  9.73086618e-01  1.04013199e+00  1.67490524e-02 -4.62946221e-03\n",
      "  1.03808337e+00  3.18732146e-02  1.03899110e+00  1.02224885e+00\n",
      "  9.77569025e-01  9.84153695e-01  9.83971381e-01 -1.58689140e-02\n",
      "  1.00824289e+00  9.35475926e-01 -3.30676804e-02  4.28742333e-02\n",
      " -2.23408402e-02  5.93632188e-03  9.92401807e-01  2.10767284e-02\n",
      "  9.88595585e-01  2.51771145e-03 -8.78430165e-03  9.93326215e-01\n",
      " -9.59511288e-03  9.80488821e-01 -4.69213672e-02 -2.67714693e-02\n",
      "  1.08654862e+00  1.03028067e+00 -1.53109582e-02 -1.74205365e-02\n",
      "  4.56767414e-02  1.01858942e+00  8.99069284e-01  1.00114693e-02\n",
      "  9.85689268e-01 -6.41960187e-03  3.15094769e-02  9.62354765e-01\n",
      "  1.00588346e+00  1.02691082e+00  1.74990127e-02 -3.97595292e-03\n",
      " -6.25056241e-03  9.80563763e-01  9.89044792e-01 -6.46920751e-02\n",
      "  9.66575219e-01  9.14391044e-01  1.00384413e+00  9.87707295e-01\n",
      "  9.50058888e-01  4.80479788e-03  2.53522204e-03  9.83043673e-01\n",
      "  1.70082110e-02  1.01762349e+00  7.92915242e-02 -2.73519421e-03\n",
      "  1.00465968e+00  8.13604930e-02  1.03239927e+00  9.89641053e-01\n",
      "  1.01476221e+00  1.60223332e-02  9.33384558e-03  9.91793913e-01\n",
      "  9.88774817e-01  1.00042678e+00  1.01032304e+00  1.42339039e-02\n",
      "  9.79090279e-01  2.45253461e-02  2.16565375e-03 -4.10021040e-03\n",
      "  1.03849058e+00  5.91831079e-03  2.94018711e-02  9.82707950e-01\n",
      "  1.01999747e+00  2.53938751e-02  9.96830702e-01  1.01692131e+00\n",
      "  9.95257526e-01  1.00992241e+00  2.70524265e-02 -4.20090382e-03\n",
      "  9.64533919e-01  9.88888881e-01  9.59022278e-01  2.03919931e-02\n",
      "  3.22200475e-02  1.04505726e+00 -3.13243069e-02 -2.90022346e-02\n",
      "  1.03507779e+00  1.02038778e+00  6.11164413e-03 -1.84110113e-02\n",
      " -7.98684842e-02  1.00599117e+00  1.06160220e+00  9.91584510e-01\n",
      "  1.05712709e+00 -5.16473343e-03 -3.16163876e-02  1.47329711e-02\n",
      "  1.00192745e+00 -1.72870086e-02  1.00618820e+00 -5.62003701e-03\n",
      "  2.11080057e-02  1.01475006e+00  4.04201403e-02  1.03293640e+00\n",
      "  2.89280518e-02 -1.05098334e-02  9.76525690e-01  1.00968411e+00\n",
      " -1.13160649e-02  9.85471377e-01  9.77771269e-01  9.97134734e-01\n",
      " -3.63456761e-02  1.01094961e+00  2.59500602e-02  1.00516080e+00\n",
      "  1.01156369e+00  2.71646973e-02  9.90941652e-01  9.22487635e-01\n",
      "  3.32931113e-02  2.09601330e-02 -6.64188365e-03  9.79993197e-01\n",
      " -8.32910865e-03  9.90001165e-01 -1.00518586e-02 -3.71544553e-02\n",
      "  9.90216650e-01  1.00222690e+00 -1.25153253e-02  4.11801867e-02\n",
      "  1.00763556e+00 -5.08650241e-04  8.05118883e-03  2.90840927e-02\n",
      "  1.01718201e+00  9.66257956e-01  1.00412597e+00 -2.81104880e-02\n",
      "  1.39282136e-02  1.06656146e+00  9.86306874e-01 -4.15065825e-02\n",
      "  1.01769029e+00  1.03128150e+00  1.02010893e+00 -1.97068976e-03\n",
      "  9.96820069e-01  1.00024834e+00  2.55737045e-03  8.96631788e-03\n",
      "  9.95966598e-01  1.01525434e+00  1.02939824e+00  2.97626590e-02\n",
      "  3.38389179e-02  1.74045162e-02 -6.82732848e-03  9.52904011e-01\n",
      " -3.34390452e-03 -1.19332064e-02 -3.73262686e-02 -5.38735957e-03\n",
      " -7.25530179e-05  1.00311821e+00  1.00912606e+00  1.64800572e-02\n",
      " -4.75939128e-03  6.48362899e-03  1.02562829e+00  4.84808627e-03\n",
      "  1.02560980e+00  9.80548259e-01  1.02665803e+00  9.92559445e-01\n",
      " -3.38914849e-03 -5.03552240e-03  1.01201241e+00  9.99133366e-01\n",
      " -1.07027981e-03  1.01663936e+00  1.04615222e+00  1.06905282e+00\n",
      "  1.00956195e+00 -2.49146084e-02  1.00608135e+00 -4.14077012e-03\n",
      "  9.95037361e-01 -7.66681238e-03 -9.46577448e-03 -4.72725933e-02\n",
      " -1.95958075e-02  1.06247226e+00  1.00362501e+00  1.01082497e+00\n",
      "  1.01333168e+00  1.52636359e-02  1.05547479e+00  9.58962356e-01\n",
      " -3.13011665e-03  9.75123234e-01 -5.54223756e-02 -1.72915302e-02\n",
      "  9.39527684e-01  1.06550089e+00 -2.66678276e-03 -4.37541565e-02\n",
      "  1.02442795e+00 -1.69063119e-02 -6.44742850e-03  3.20124128e-03\n",
      "  9.59218291e-01  9.70363837e-01  9.82665387e-01 -3.42032196e-02\n",
      "  9.75648864e-01 -4.15044627e-02 -4.64873397e-02  2.69593840e-02\n",
      "  3.17177596e-02 -1.68467230e-02  1.00578892e+00  4.27816164e-02\n",
      " -3.31617582e-02  7.76405971e-03  8.99634937e-03  2.84289171e-02\n",
      "  1.02225427e+00 -2.34575925e-03  2.89343171e-03  1.01330924e+00\n",
      " -3.72568266e-03  1.01003597e+00 -1.41051474e-02  1.02290816e+00\n",
      "  6.70687998e-04  2.57439527e-02 -9.52394323e-03  4.25644194e-02\n",
      "  9.88323683e-01  1.02327022e+00  1.01292791e+00  8.00844163e-04\n",
      "  3.21896053e-02  9.54517199e-03 -2.02250898e-02 -3.69178207e-02\n",
      "  9.70237427e-01  1.04014698e+00  1.00156712e+00  9.92354138e-01\n",
      "  9.90609653e-01  1.50639355e-02  1.02238111e+00  9.85964425e-01\n",
      " -4.08954389e-02  1.02710053e+00  9.90849712e-01  1.07279884e+00\n",
      "  1.02130162e+00 -7.44276299e-03  1.00399374e+00  9.96173494e-01\n",
      "  1.00525595e+00  1.02618075e+00  1.00829026e+00  3.03025969e-03\n",
      "  1.01983829e+00  8.24621340e-03  1.05801210e+00  1.00906383e+00\n",
      "  9.99009099e-01  4.47219818e-02  1.00886258e+00  9.82935163e-01\n",
      "  2.37228668e-04  3.32680668e-02  9.95107718e-01 -2.20601829e-02\n",
      "  9.76780305e-01 -6.44522287e-03  1.05555066e+00  9.89319750e-01\n",
      "  1.01702633e+00  6.33158360e-03  1.01214566e+00  9.97842161e-01\n",
      "  1.00187424e+00 -1.06234987e-02  3.09645955e-02 -1.11790416e-02\n",
      "  1.01247564e+00  2.33960770e-02 -1.81795303e-02 -3.68272318e-02\n",
      "  9.99904367e-01  3.37498217e-02  1.03882087e+00  9.56811638e-01\n",
      "  9.69131787e-01  7.47561572e-03  1.03581250e+00  1.03946644e+00\n",
      "  1.01961210e+00  1.00551368e+00  9.94871253e-01  8.98827832e-03\n",
      "  2.33293835e-02  1.00340883e+00 -3.11286769e-02 -9.04460414e-03\n",
      " -2.99236398e-04  9.68585284e-01  9.53109101e-01  8.56670885e-03\n",
      "  1.29795918e-02 -2.32259482e-03  9.93065072e-01  1.03943975e+00\n",
      "  2.60900678e-02  2.88339866e-02  9.92174725e-01  3.22894500e-02\n",
      " -8.64893352e-02  1.34080714e-02  2.57992742e-02  9.54832997e-01\n",
      "  9.67770427e-01  1.02175449e+00  9.37445013e-01 -8.28353224e-03\n",
      " -5.43564213e-02  1.03290914e+00  9.83957498e-01  1.01806923e+00\n",
      "  9.98656445e-01  1.17058392e-02  1.20871912e-02  1.00088559e+00\n",
      "  1.02269561e+00  1.92283876e-02 -6.83890898e-03  1.03390264e+00\n",
      " -3.71214607e-02  1.04990557e-02 -1.94400741e-02  9.82996386e-01\n",
      "  9.85176972e-01 -3.95405370e-02 -1.42729602e-02  1.02703986e+00\n",
      " -1.44856529e-02  9.65764693e-01  1.27170528e-02 -2.84830041e-03\n",
      "  9.58763093e-01  1.01446306e+00  1.00772011e+00  1.01548419e+00\n",
      "  1.01227918e+00 -7.07372073e-03 -2.94516108e-02 -6.17775552e-02\n",
      "  1.01527006e+00  8.43691848e-03  9.92826076e-01 -1.16972238e-02\n",
      "  4.05760932e-02 -3.07165849e-02  1.00367759e+00 -1.03917825e-02\n",
      "  1.01803610e+00  9.87907095e-01  9.92737874e-01 -1.32917521e-02\n",
      "  1.01187138e+00  1.95791330e-02  9.97461678e-01  1.40371018e-02\n",
      "  1.00776534e+00  2.75142446e-02 -5.48200894e-02  1.00303377e+00\n",
      "  9.86940809e-01  9.86966027e-01 -6.87802952e-02  3.39057334e-02\n",
      "  9.79346361e-01  1.05733253e+00  1.02244131e+00  9.61005471e-01\n",
      "  1.01486016e+00  1.14769965e-02  9.66088511e-01  9.96203254e-01\n",
      "  9.33219775e-01 -2.74058491e-02  9.59707900e-01 -1.57091794e-02\n",
      "  6.14819089e-04  1.51323669e-02  9.96294851e-01 -2.85321063e-02\n",
      "  1.03936644e+00  1.01855934e+00  1.00770564e+00  9.85524797e-01\n",
      " -9.17160664e-05  2.56173743e-02  8.03400225e-03 -5.26851138e-02\n",
      "  1.01982912e+00  1.03045363e+00 -1.25025931e-02  9.88551974e-01\n",
      " -3.69918008e-02  9.98050914e-01  9.66168366e-01  1.01465918e+00\n",
      "  1.04308287e+00  4.52741867e-02 -9.98697460e-03  9.59786673e-01\n",
      " -9.15131220e-02  9.64281366e-01 -4.34377295e-02 -4.15223565e-02\n",
      "  1.04496850e-02  9.30769281e-01  1.00498024e+00 -1.24589484e-02\n",
      "  8.62497190e-03  3.53854431e-02  1.00512549e+00 -7.47721848e-03\n",
      "  2.78972827e-02  8.06517734e-03  1.01698860e+00  1.03684066e+00\n",
      "  1.04048089e+00 -1.49107210e-02  1.01731072e+00  1.02953004e+00\n",
      " -9.28702969e-03  9.92875526e-01 -5.75675308e-02  5.42348647e-03\n",
      "  1.02408006e+00  8.31225202e-02 -3.67420651e-02 -1.28556465e-02\n",
      "  1.62955914e-02  1.27253022e-02  3.59950753e-02  1.86101296e-02\n",
      " -1.28598216e-02  1.01538321e+00  1.01328533e+00  9.82390045e-01\n",
      "  1.02572746e+00 -3.44218400e-02  1.01875957e+00  9.84315164e-01\n",
      "  9.79645774e-01  9.81224483e-01  5.12863964e-02  9.16511160e-01\n",
      "  1.08219982e-02 -5.06030653e-02 -1.64454937e-03  1.01432702e+00\n",
      "  7.52589933e-04  2.20783360e-02  9.50192962e-01  8.91816132e-03\n",
      "  2.44397010e-02  1.43443656e-02  1.02046766e+00  1.00822003e+00\n",
      "  3.55006656e-02  1.04654760e+00 -1.05105338e-02  3.32360380e-02\n",
      "  1.02773554e+00 -1.65730376e-03 -2.47657934e-02  9.29108173e-03\n",
      "  3.75569712e-02  9.86149817e-01 -2.33143431e-03  1.02105568e+00\n",
      " -1.39310794e-02  3.77508389e-02 -3.03969855e-02 -2.43816919e-02\n",
      "  3.65713592e-03  1.45321254e-02  2.78517633e-02  9.67150535e-01\n",
      "  1.03557708e+00  1.72939801e-02  1.04430913e+00 -1.39864132e-02\n",
      "  9.46544095e-01  2.87859479e-02  1.05848018e+00 -7.85627547e-04\n",
      "  1.00506481e+00  1.02256546e+00  1.01512218e+00 -5.65735151e-03\n",
      "  9.96736236e-01  1.03553909e+00  1.05585361e+00 -5.86329760e-02\n",
      "  9.15824958e-01  9.88829832e-01 -1.50262514e-02  5.21724786e-03\n",
      "  4.21244436e-02  1.28782365e-02  1.01677221e+00  1.11730842e-02\n",
      "  9.61353406e-01 -2.73827728e-02 -5.45011957e-03  9.55862310e-01\n",
      "  3.71244565e-02  9.66754988e-01  1.02033099e+00  1.01891665e+00\n",
      "  2.32638704e-02 -1.96247778e-02  1.02507679e+00  1.01331036e+00\n",
      "  1.04787131e+00 -2.80663400e-02 -1.09160333e-02  9.82474106e-01\n",
      "  9.66866332e-01  9.65482030e-01  9.99693498e-01  3.49837638e-02\n",
      "  1.00921257e+00  1.64015778e-02 -4.65598243e-02  1.03580133e+00\n",
      "  5.91325604e-03 -3.05665868e-02  1.02607324e+00  1.00574559e+00\n",
      "  9.95616085e-01  1.02740980e+00 -7.41292397e-03  7.54494025e-02\n",
      "  9.78244095e-01  3.98356823e-02  9.48123361e-01  9.93034253e-01\n",
      "  2.51494556e-02  9.73171527e-01 -3.41116977e-03  2.12692963e-03\n",
      "  2.53116958e-02 -2.12654169e-02  9.32657591e-01 -2.01567501e-02\n",
      "  4.93280923e-02  1.03260783e+00  9.99833250e-01 -1.63155588e-02\n",
      " -6.42575770e-03  9.61509502e-01 -3.13632874e-02  2.41335188e-02\n",
      " -2.42900890e-02  5.55503991e-03  1.00365526e+00  2.06128627e-02\n",
      "  1.02738547e+00 -8.14314393e-04  1.04970883e+00  9.94502115e-01\n",
      "  4.72168713e-02  1.01170902e+00 -2.71142685e-02  2.77243487e-02\n",
      "  1.00545476e+00  1.10362183e-02 -3.15451267e-02  1.00085278e+00\n",
      " -2.60775416e-02  1.03257768e+00  3.08198141e-02  1.04103771e+00\n",
      "  9.20379872e-03  9.94634272e-01  9.95634369e-01  1.04867955e+00\n",
      "  8.42237304e-03  1.02451344e+00  3.71406684e-03  9.48662941e-01\n",
      "  9.98100733e-01  1.02217904e+00  5.89007775e-02  1.28120745e-02\n",
      " -1.53774806e-02  9.44322271e-01  1.77055526e-03  9.92985150e-01\n",
      "  1.00044017e+00 -4.43267350e-02  5.42948277e-03  4.18723561e-02\n",
      "  9.43086108e-01  1.04005070e+00 -4.40076339e-02  9.74457872e-01\n",
      " -1.91776418e-02  9.98881395e-01 -1.59330270e-02  3.73450067e-03\n",
      "  9.89565785e-01  3.88967247e-02  1.03027801e+00  1.03854040e+00\n",
      " -1.40577553e-02  1.04970937e+00  1.01508613e+00 -3.50079811e-02\n",
      "  9.86727971e-01  9.99943103e-01  9.77661457e-01  7.64411346e-03\n",
      "  1.78038920e-02  1.26864364e-04 -2.45336631e-02  3.19957985e-03\n",
      "  3.03737841e-03 -3.35016901e-02  9.49430818e-01  9.60903143e-01\n",
      "  9.89672453e-01  9.62272738e-01 -3.10949177e-02 -8.78812044e-03\n",
      "  9.84796237e-01  9.95739290e-01 -1.06056788e-02 -1.28664474e-02\n",
      " -4.27459634e-02  9.66867931e-01 -4.83031923e-02  9.77609950e-01\n",
      "  1.01019226e+00 -4.00856045e-02 -5.07895030e-02  2.59186815e-02\n",
      "  1.03796892e+00  3.46519528e-02  9.91907038e-01  9.73186632e-01\n",
      "  3.57560006e-03 -2.08149035e-02  9.58476882e-01 -5.58840063e-03\n",
      "  6.87810231e-02  9.88635533e-01 -1.01107897e-03  9.89288192e-01\n",
      "  1.00591425e+00  9.76963355e-01 -2.20418752e-02  1.02225756e+00\n",
      "  9.84177860e-01 -3.56831333e-02  9.86404899e-01  9.88012336e-01\n",
      "  1.00368863e+00  9.96627617e-01  1.01024797e+00 -4.07729801e-02\n",
      " -2.58181632e-02  1.00327020e+00 -5.28498567e-02  2.59395896e-02\n",
      "  8.92010959e-02  3.11831457e-03  4.12399977e-02  2.01697058e-02\n",
      "  4.34092069e-02  1.02470274e+00  9.60871911e-01 -1.03031397e-02\n",
      "  1.00486043e+00  9.78145166e-01  1.02950380e+00  9.36542289e-01\n",
      "  9.97482473e-01 -1.79306115e-02  1.03881435e+00  9.91608860e-01\n",
      " -5.69845411e-03 -2.12458563e-02  9.53235513e-01  9.64136463e-01\n",
      " -3.74942624e-02  1.00265001e+00  1.04774114e+00  9.95960462e-01\n",
      "  1.52228079e-02  1.00703412e+00  6.84499992e-03 -3.24310824e-02\n",
      " -1.42953602e-02  9.67106365e-01  9.47825666e-01 -2.71019087e-02\n",
      "  9.95025860e-01  3.84460699e-02  1.00928675e+00  1.02374904e+00\n",
      "  9.72459776e-01  9.27719590e-01  5.05142902e-02 -2.56719078e-02\n",
      "  1.04572528e+00  9.87212858e-01 -3.26455539e-02  1.00836560e+00\n",
      "  1.47990867e-02 -5.63830149e-03  1.01522025e+00  1.03262439e+00\n",
      " -4.29275060e-02  1.01567923e+00 -5.61091792e-03  3.43598667e-02\n",
      "  1.01426783e+00  3.48150704e-02  9.73224244e-01 -9.38946272e-03\n",
      "  1.02806321e+00  1.01492663e+00  8.13744108e-03 -4.04773052e-02\n",
      " -1.61489022e-02  1.00377198e+00  1.12887955e-02  6.15938797e-03\n",
      "  4.62859166e-02  1.04492183e+00 -6.23316039e-02  2.45470650e-02\n",
      "  1.02010932e+00 -2.20980172e-02 -3.53418287e-02  5.07274962e-02\n",
      "  2.18054740e-02  1.04805783e+00 -2.51191202e-02  4.49030468e-03\n",
      " -3.03860494e-02  1.04904551e+00  2.15006695e-02  2.28682518e-03\n",
      "  9.88315343e-01  9.78967520e-01  9.80873834e-01  1.01923914e+00\n",
      "  9.84377301e-01  4.75781286e-02  2.73057165e-02  9.98224301e-01\n",
      "  1.27057650e-02  1.26359951e-03  3.10167333e-02 -5.26675646e-02\n",
      " -1.84017019e-02 -2.85047147e-02  1.57168925e-02  1.02271124e+00\n",
      "  2.66373490e-02  2.72564334e-02  1.77112937e-02  4.66062148e-03\n",
      " -2.52696223e-03 -2.33292216e-02  9.63487522e-01  1.02141204e+00\n",
      "  3.43034002e-02  9.75135090e-01  2.76356379e-02 -1.19325506e-02\n",
      "  3.66437821e-03 -3.26093458e-02 -3.78182411e-02 -4.29724024e-02\n",
      " -5.30254739e-03  9.75808512e-01  9.85805906e-01  1.75282435e-02\n",
      " -6.97007438e-02  9.67955542e-01  1.01384839e+00 -1.88072587e-02\n",
      "  9.98341197e-01  9.88367683e-01 -1.40830001e-02  1.03998605e+00\n",
      "  1.00811265e+00  4.33222320e-02 -2.79718765e-02  3.05240139e-02\n",
      "  1.00713811e+00  1.06082027e+00 -6.07222557e-03  1.01514627e+00\n",
      "  1.04266467e+00  9.75973660e-01  1.04508874e+00  3.48753088e-03\n",
      "  2.32665301e-03  1.03647781e-02  1.10420491e-02  9.98858352e-01\n",
      "  9.94506755e-01  1.02232777e+00  5.42383660e-03  1.01687520e+00\n",
      "  5.53223542e-03  9.98288816e-01  9.39594102e-01  8.34419234e-03\n",
      " -2.85771722e-02  9.37527145e-01 -1.93351779e-02  1.02045989e+00\n",
      "  3.92787453e-03  2.04717060e-02  9.94910427e-01 -3.12366440e-03\n",
      "  1.02609381e+00 -6.24722094e-03  9.98032150e-01  1.02355635e+00\n",
      "  9.88390700e-01  3.46657217e-02  5.63750325e-04 -4.69936303e-03\n",
      "  7.77256456e-03 -2.91620826e-02  9.49985040e-01  8.63975108e-03\n",
      "  1.00223083e+00  1.07782061e+00  1.97217417e-02  9.71179103e-01\n",
      "  1.00739895e+00 -1.24600983e-02 -1.73864382e-02 -7.22993892e-02\n",
      "  9.89834565e-01  1.04844043e+00  1.06548025e+00  9.70132928e-01\n",
      "  9.52878283e-01  1.01353684e+00  1.01028292e+00  1.01481387e+00] <map object at 0x13907e2c0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape () instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gaussian_generalization_error_list \u001b[39m=\u001b[39m [eval_const_rounds(\u001b[39mround\u001b[39m, Mechanism(mechanism_type \u001b[39m=\u001b[39m Mechanism\u001b[39m.\u001b[39mMechanismType\u001b[39m.\u001b[39mGAUSSIAN, sigma \u001b[39m=\u001b[39m \u001b[39m0.03\u001b[39m), stepped_non_adaptive_num)\n\u001b[1;32m      2\u001b[0m                                       \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(gaussian_generalization_error_list, axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m baseline_generalization_error_list \u001b[39m=\u001b[39m [eval_const_rounds(\u001b[39mround\u001b[39m, Mechanism(mechanism_type \u001b[39m=\u001b[39m Mechanism\u001b[39m.\u001b[39mMechanismType\u001b[39m.\u001b[39mNONE), stepped_non_adaptive_num)\n\u001b[1;32m      7\u001b[0m                                       \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gaussian_generalization_error_list \u001b[39m=\u001b[39m [eval_const_rounds(\u001b[39mround\u001b[39;49m, Mechanism(mechanism_type \u001b[39m=\u001b[39;49m Mechanism\u001b[39m.\u001b[39;49mMechanismType\u001b[39m.\u001b[39;49mGAUSSIAN, sigma \u001b[39m=\u001b[39;49m \u001b[39m0.03\u001b[39;49m), stepped_non_adaptive_num)\n\u001b[1;32m      2\u001b[0m                                       \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(gaussian_generalization_error_list, axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m baseline_generalization_error_list \u001b[39m=\u001b[39m [eval_const_rounds(\u001b[39mround\u001b[39m, Mechanism(mechanism_type \u001b[39m=\u001b[39m Mechanism\u001b[39m.\u001b[39mMechanismType\u001b[39m.\u001b[39mNONE), stepped_non_adaptive_num)\n\u001b[1;32m      7\u001b[0m                                       \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36meval_const_rounds\u001b[0;34m(round, mechanism, stepped_non_adaptive_num)\u001b[0m\n\u001b[1;32m     13\u001b[0m generalization_error_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m train_size \u001b[39min\u001b[39;00m stepped_non_adaptive_num:\n\u001b[0;32m---> 15\u001b[0m     generalization_error_list\u001b[39m.\u001b[39mappend(eval_const(\u001b[39mround\u001b[39;49m, train_size, mechanism))\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m generalization_error_list\n",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m, in \u001b[0;36meval_const\u001b[0;34m(round, train_size, mechanism)\u001b[0m\n\u001b[1;32m      3\u001b[0m x_train, y_train \u001b[39m=\u001b[39m x_population[:train_size], y_population[:train_size]    \n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m MechanizedLogisticRegression(C \u001b[39m=\u001b[39m BEST_C, max_iter \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m, mechanism \u001b[39m=\u001b[39m mechanism)\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Predict\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_valid)\n",
      "Cell \u001b[0;32mIn[24], line 84\u001b[0m, in \u001b[0;36mMechanizedLogisticRegression.fit\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmechanism\u001b[39m.\u001b[39mmechanism_type \u001b[39m==\u001b[39m  Mechanism\u001b[39m.\u001b[39mMechanismType\u001b[39m.\u001b[39mGAUSSIAN:\n\u001b[1;32m     83\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39min Gaussian Mechanized Logistic Regression\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_gaussian(x_train, y_train)\n\u001b[1;32m     86\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmechanism\u001b[39m.\u001b[39mmechanism_type \u001b[39m==\u001b[39m  Mechanism\u001b[39m.\u001b[39mMechanismType\u001b[39m.\u001b[39mTHRESHOLD:\n\u001b[1;32m     87\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39min Threshold Mechanized Logistic Regression\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 66\u001b[0m, in \u001b[0;36mMechanizedLogisticRegression.fit_gaussian\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m     62\u001b[0m noised_y \u001b[39m=\u001b[39m (\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x : \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m, noised_y))\n\u001b[1;32m     63\u001b[0m \u001b[39mprint\u001b[39m( y_train \u001b[39m+\u001b[39m y_noise, noised_y)\n\u001b[0;32m---> 66\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(MechanizedLogisticRegression, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(noised_x, noised_y)\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LogisticRegression):\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1197\u001b[0m     X,\n\u001b[1;32m   1198\u001b[0m     y,\n\u001b[1;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1203\u001b[0m )\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1143\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m-> 1143\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1144\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, estimator_name\u001b[39m=\u001b[39mestimator_name)\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1194\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[1;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[0;32m-> 1202\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[1;32m   1204\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape () instead."
     ]
    }
   ],
   "source": [
    "gaussian_generalization_error_list = [eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.GAUSSIAN, sigma = 0.03), stepped_non_adaptive_num)\n",
    "                                      for _ in range(100)]\n",
    "print(np.mean(gaussian_generalization_error_list, axis = 0))\n",
    "\n",
    "\n",
    "baseline_generalization_error_list = [eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.NONE), stepped_non_adaptive_num)\n",
    "                                      for _ in range(100)]\n",
    "\n",
    "print(np.mean(baseline_generalization_error_list, axis = 0))\n",
    "\n",
    "\n",
    "\n",
    "threshold_generalization_error_list = [eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.7, threshold = 0.8), stepped_non_adaptive_num)\n",
    "                                       for _ in range(100)]\n",
    "\n",
    "print(threshold_generalization_error_list)\n",
    "print(np.mean(threshold_generalization_error_list, axis = 0))\n",
    "\n",
    "data_split_generalization_error_list = [eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.DATASPLIT), stepped_non_adaptive_num)\n",
    "                                        for _ in range(100)]\n",
    "print(np.mean(data_split_generalization_error_list, axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(baseline_generalization_error_list, axis = 0))\n",
    "print(np.mean(gaussian_generalization_error_list, axis = 0))\n",
    "print(np.mean(threshold_generalization_error_list, axis = 0))\n",
    "\n",
    "print(np.mean(data_split_generalization_error_list, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_error(rounds, generalization_error, mechanism, color = None):\n",
    "    plt.plot(rounds, generalization_error, color, label = mechanism)\n",
    "    plt.xlabel(\"Queries\")\n",
    "    plt.ylabel(\"RMSE (Generalization Error) for adaptive queries\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "plt.figure()\n",
    "x_range = stepped_non_adaptive_num\n",
    "plot_error(x_range, baseline_generalization_error_list, \"Emripircal\", 'g')\n",
    "plot_error(x_range, gaussian_generalization_error_list, \"Gaussian\", 'r')\n",
    "plot_error(x_range, threshold_generalization_error_list, \"Threshold - Adaptfun\", \"y\")\n",
    "plt.savefig(\"../plots/c_adaptivity.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_generalization_error_list = eval_const_rounds(round, Mechanism(mechanism_type = Mechanism.MechanismType.THRESHOLD, sigma = 0.1, hold_frac = 0.7, threshold = 0.8), stepped_non_adaptive_num)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
