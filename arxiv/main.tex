\documentclass[a4paper,11pt]{article}
\usepackage[table]{xcolor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% INPUTTING SELF DEFINED COMMANDS, SELF IMPORTED PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{prelude}
\input{ldefs}
\newcommand{\THESYSTEM}{\textsf{AdaptFun}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%% FINISHING INPUTTING SELF DEFINED COMMANDS, SELF IMPORTED PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\begin{document}
\title{Program Analysis for Adaptivity Analysis}

\author{}

\date{}
\maketitle

\begin{abstract}
    Data analyses are usually designed to identify some property of the population from which the data are drawn, generalizing beyond the specific data sample. For this reason, data analyses are often designed in a way that guarantees that they produce a low generalization error.
    That is, they are designed so that the result of a data analysis run on a sample data does not differ too much from the result one would achieve by running the analysis over the entire population. 
   
   An adaptive data analysis can be seen as a process composed by multiple queries interrogating some data, where the choice of which query to run next may rely on the results of previous queries. 
   The generalization error of each individual query/analysis can be controlled by using an array of well-established statistical techniques.
   However, when queries are arbitrarily composed, the different errors can propagate through the chain of different queries and bring to high generalization error. 
   To address this issue, data analysts are designing several techniques that not only guarantee bounds on the generalization errors of single queries, but that also guarantee bounds on the generalization error of the composed analyses. 
   The choice of which of these techniques to use, often depends on the chain of queries that an adaptive data analysis can generate.
   
   In this work, we consider adaptive data analyses implemented as while-like programs and we design a program analysis which can help with identifying which technique to use to control their generalization error. 
   More specifically, we formalize the intuitive notion of \emph{adaptivity} as a quantitative property of programs. 
   We do this because the adaptivity level of a data analysis is a key measure to choose the right technique. 
   Based on this definition, we design a program analysis for soundly approximating this quantity.
   The program analysis generates a representation of the data analysis as a weighted dependency graph, where the weight is an upper bound on the number of times each variable can be reached, and uses a path search strategy to guarantee an upper bound on the adaptivity. 
   We implement our program analysis  and show that it can help to analyze the adaptivity of several concrete data analyses with different adaptivity structures.
\end{abstract}

%
\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction and Overview %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Introduction}
\label{sec:intro}
\input{intro}
\section{Overview}
\label{sec:overview}
\input{overview}
\clearpage

% %
\section{{\tt Query While} Language}
\label{sec:language}
\input{language}
\clearpage
% %
% \section{Event and Trace}
% \input{event}
% \input{trace}
% \clearpage
% %
\section{Definition of Adaptivity}
\label{sec:adaptivity}
\input{adapt}
\clearpage
% % 
\section{The Adaptivity Analysis Algorithm - {\THESYSTEM}}
\label{sec:algorithm}
\input{adaptfun}
% % % % 

\section{Examples}
\label{sec:examples}
\input{examples}

\section{Evaluation Results}
\input{evaluation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Related Work and Conclusion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related Work}
\input{relatedwork}
\section{Conclusion and future works}
\input{conclusion}

%
\clearpage
\appendix
\addcontentsline{toc}{section}{Appendices}
\section*{Appendices}
\input{appendix}
\bibliographystyle{plain}
\bibliography{adaptivity.bib}

\end{document}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
